{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import random\n",
        "import json\n",
        "import nltk \n",
        "import csv\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk  # $ pip install nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import cmudict  # >>> nltk.download('cmudict')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from spellchecker import SpellChecker # $ pip install pyspellchecker\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
        "\n",
        "from beliefbank_data.utils import generate_assertion, generate_question, find_constraints, generate_inverse_question, generate_question_with_context\n",
        "import correction_utils"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1647097059238
        }
      },
      "id": "f75d45a7-8f30-4cf7-b64e-5645782ef09e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {},
      "id": "83360dd8-9e5a-48a4-8274-0c70e3a0361d"
    },
    {
      "cell_type": "code",
      "source": [
        "constraints_path = \"beliefbank_data/constraints_v2.json\"\n",
        "facts_path = \"beliefbank_data/silver_facts.json\""
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1647097059451
        }
      },
      "id": "03374e1c-dff7-49d5-847b-0a6816c6a5dd"
    },
    {
      "cell_type": "code",
      "source": [
        "constraints = json.load(open(constraints_path))\n",
        "facts = json.load(open(facts_path))"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1647097059665
        }
      },
      "id": "05c60643-c341-4af6-9459-c8458700b72c"
    },
    {
      "cell_type": "code",
      "source": [
        "# entities = list(facts.keys())\n",
        "# random.shuffle(entities)\n",
        "# dev_size = 65\n",
        "# dev_entities = sorted(entities[:dev_size])\n",
        "# eval_entities = sorted(entities[dev_size:])\n",
        "# with open(\"beliefbank_data/dev_entities.txt\", \"w\") as f:\n",
        "#     f.writelines([e + '\\n' for e in dev_entities])\n",
        "# with open(\"beliefbank_data/eval_entities.txt\", \"w\") as f:\n",
        "#     f.writelines([e + '\\n' for e in eval_entities])\n",
        "\n",
        "with open(\"beliefbank_data/dev_entities.txt\", \"r\") as f:\n",
        "    dev_entities = [e.strip() for e in f.readlines()]\n",
        "print(dev_entities)\n",
        "\n",
        "# with open(\"beliefbank_data/eval_entities.txt\", \"r\") as f:\n",
        "#     eval_entities = [e.strip() for e in f.readlines()]\n",
        "# print(eval_entities)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['american bison', 'baboon', 'birch', 'buck', 'bull', 'calf', 'camel', 'carnivore', 'carp', 'cheetah', 'chick', 'chimpanzee', 'cock', 'crocodile', 'dog', 'dolphin', 'domestic ass', 'duck', 'earthworm', 'elephant', 'european wolf spider', 'foxhound', 'frog', 'gazelle', 'gecko', 'german shepherd', 'giant panda', 'giraffe', 'gladiolus', 'hen', 'horse', 'hound', 'howler monkey', 'hummingbird', 'jaguar', 'lamb', 'leopard', 'lion', 'livestock', 'llama', 'magpie', 'midge', 'mink', 'mullet', 'myna', 'new world blackbird', 'orchid', 'owl', 'ox', 'penguin', 'peony', 'pigeon', 'poodle', 'puppy', 'rabbit', 'rat', 'reptile', 'robin', 'rose', 'salamander', 'starling', 'tiger', 'turkey', 'whale', 'zebra']\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1647097059861
        }
      },
      "id": "f4a25158-8d99-4088-b240-51b5b6423334"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constraints checking"
      ],
      "metadata": {},
      "id": "a40f96b8-fa0b-4071-8fb3-d649112a23f8"
    },
    {
      "cell_type": "code",
      "source": [
        "constraints_yy = set() # A implies B\n",
        "constraints_yn = set() # A implies not B\n",
        "for link in constraints['links']:\n",
        "    s = link['source']\n",
        "    t = link['target']\n",
        "    if link['weight'] == 'yes_yes':\n",
        "        if link['direction'] == 'forward':\n",
        "            constraints_yy.add((s, t))\n",
        "        else:\n",
        "            constraints_yy.add((t, s))\n",
        "    else:\n",
        "        constraints_yn.add((s, t))\n",
        "        constraints_yn.add((t, s))"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1647097060058
        }
      },
      "id": "dc706745-546a-4687-b3a7-5bdf45dc19a0"
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(constraints_yy))\n",
        "print(len(constraints_yn))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1836\n774\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1647097060253
        }
      },
      "id": "9d49487f-ddd8-42ae-882a-f8d05cc1b708"
    },
    {
      "cell_type": "markdown",
      "source": [
        "AB in yn --> BA in yn\n",
        "AB in yy, BC in yy --> AC in yy\n",
        "AB in yy, BC in yn --> AC in yn\n",
        "# AB in yn, CB in yy --> AC in yn "
      ],
      "metadata": {},
      "id": "74a268da-7f64-4117-8453-7f734ac8f8e1"
    },
    {
      "cell_type": "code",
      "source": [
        "dict_yy = {}\n",
        "for s, t in constraints_yy:\n",
        "    if s in dict_yy:\n",
        "        dict_yy[s].add(t)\n",
        "    else:\n",
        "        dict_yy[s] = {t}\n",
        "dict_yn = {}\n",
        "for s, t in constraints_yn:\n",
        "    if s in dict_yn:\n",
        "        dict_yn[s].add(t)\n",
        "    else:\n",
        "        dict_yn[s] = {t}"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1647097060460
        }
      },
      "id": "e24c37f9-da8e-4a01-8e8e-a2540facc1ac"
    },
    {
      "cell_type": "code",
      "source": [
        "depth = 10\n",
        "len_yy = [len(constraints_yy)]\n",
        "len_yn = [len(constraints_yn)]\n",
        "for d in range(depth-1):\n",
        "    temp_yy = copy.deepcopy(dict_yy)\n",
        "    temp_yn = copy.deepcopy(dict_yn)\n",
        "    for a, bs in dict_yy.items():\n",
        "        for b in bs:\n",
        "            for c in dict_yy.get(b, set()):\n",
        "                if a == c:\n",
        "                    continue\n",
        "                temp_yy[a].add(c)\n",
        "            for c in dict_yn.get(b, set()):\n",
        "                if a == c:\n",
        "                    continue\n",
        "                if a in temp_yn:\n",
        "                    temp_yn[a].add(c)\n",
        "                else:\n",
        "                    temp_yn[a] = {c}\n",
        "                if c in temp_yn:\n",
        "                    temp_yn[c].add(a)\n",
        "                else:\n",
        "                    temp_yn[c] = {a}\n",
        "    del dict_yy\n",
        "    del dict_yn\n",
        "    dict_yy = temp_yy\n",
        "    dict_yn = temp_yn\n",
        "    len_yy.append(sum([len(v) for v in dict_yy.values()]))\n",
        "    len_yn.append(sum([len(v) for v in dict_yn.values()]))"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1647097060656
        }
      },
      "id": "a8b0e11c-5331-4f08-aae0-db6a68157baa"
    },
    {
      "cell_type": "code",
      "source": [
        "for s, ts in dict_yy.items():\n",
        "    for t in ts:\n",
        "        constraints_yy.add((s, t))\n",
        "for s, ts in dict_yn.items():\n",
        "    for t in ts:\n",
        "        constraints_yn.add((s, t))\n",
        "constraints_nn = set([(t, s) for s, t in constraints_yy])"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1647097060858
        }
      },
      "id": "5e70cb4a-6fdb-412a-8c04-38a8351842bd"
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(constraints_yy))\n",
        "print(len(constraints_yn))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "3931\n11346\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1647097061055
        }
      },
      "id": "736fe796-8a9f-470f-9f74-4565eb1a953a"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Constraints vs depth\")\n",
        "plt.plot(len_yy, label=\"yy\")\n",
        "plt.plot(len_yn, label=\"yn\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1647097061317
        }
      },
      "id": "09ce6b7f-8ff5-4599-b7bb-5bebeade6c26"
    },
    {
      "cell_type": "code",
      "source": [
        "for c1, c2 in constraints_yn:\n",
        "    if c1 == c2:\n",
        "        print(c1, c2)\n",
        "        break"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1647097061514
        }
      },
      "id": "cfe9b264-1408-4d9e-b50b-4443d6dfbe5a"
    },
    {
      "cell_type": "code",
      "source": [
        "dict_nn = {}\n",
        "for s, t in constraints_nn:\n",
        "    if s in dict_nn:\n",
        "        dict_nn[s].add(t)\n",
        "    else:\n",
        "        dict_nn[s] = {t}"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1647097061712
        }
      },
      "id": "c368e6e7-7bd9-42e7-86f1-6ff58fee48ca"
    },
    {
      "cell_type": "code",
      "source": [
        "neighbors = {}\n",
        "num_neighbors = {}\n",
        "for s in list(dict_yy.keys()) + list(dict_yn.keys()) + list(dict_nn.keys()):\n",
        "    neighbors[s] = dict_yy.get(s, set()).union(dict_yn.get(s, set())).union(dict_nn.get(s, set()))\n",
        "    num_neighbors[s] = len(neighbors[s])"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1647097061905
        }
      },
      "id": "a6eb7323-ed08-4431-82c0-db99d05c82a3"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(num_neighbors.values(), bins=range(0, max(num_neighbors.values()) + 1, 20))\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1647097062417
        }
      },
      "id": "3fa7c0ef-3fef-474a-8d3e-741e641844f7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case | Equivalent implications   | Contradictory case\n",
        "a    | 1 -> not 2 == 2 -> not 1  | 1 & 2\n",
        "b    | 1 -> 2 == not 2 -> not 1  | 1 & not 2\n",
        "c    | 2 -> 1 == not 1 -> not 2  | not 1 & 2\n",
        "d    | not 1 -> 2 == not 2 -> 1  | not 1 & not 2"
      ],
      "metadata": {},
      "id": "7d1a220d-4e83-40a4-bb48-2599e043036f"
    },
    {
      "cell_type": "code",
      "source": [
        "def check_constraints(relation1, true1, relation2, true2):\n",
        "    # Is (relation1, true1) & (relation2, true2)  \n",
        "    if true1 and true2: # Case a\n",
        "        implies12 = (relation1, relation2) in constraints_yy\n",
        "        implies21 = (relation2, relation1) in constraints_yy\n",
        "        contradicts = (relation1, relation2) in constraints_yn or (relation2, relation1) in constraints_yn\n",
        "    elif true1 and not true2: # Case b\n",
        "        implies12 = (relation1, relation2) in constraints_yn or (relation2, relation1) in constraints_yn\n",
        "        implies21 = False\n",
        "        contradicts = (relation1, relation2) in constraints_yy\n",
        "    elif not true1 and true2: # Case c\n",
        "        implies12 = False\n",
        "        implies21 = (relation1, relation2) in constraints_yn or (relation2, relation1) in constraints_yn\n",
        "        contradicts = (relation2, relation1) in constraints_yy\n",
        "    else: # Case d\n",
        "        implies12 = (relation2, relation1) in constraints_yy\n",
        "        implies21 = (relation1, relation2) in constraints_yy\n",
        "        contradicts = False\n",
        "    return implies12, implies21, contradicts"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1647097062636
        }
      },
      "id": "34aa4611-b2e3-46d6-8f7e-dbcebb92bf97"
    },
    {
      "cell_type": "code",
      "source": [
        "print(check_constraints(\"IsA,animal\", True, \"IsA,mammal\", True))\n",
        "print(check_constraints(\"IsA,animal\", True, \"IsA,mammal\", False))\n",
        "print(check_constraints(\"IsA,animal\", False, \"IsA,mammal\", True))\n",
        "print(check_constraints(\"IsA,animal\", False, \"IsA,mammal\", False))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(False, True, False)\n(False, False, False)\n(False, False, True)\n(True, False, False)\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1647097062836
        }
      },
      "id": "3bbd05e6-2234-4a56-9239-6295c3cbfcf1"
    },
    {
      "cell_type": "code",
      "source": [
        "print(check_constraints(\"IsA,animal\", True, \"IsA,candy\", True))\n",
        "print(check_constraints(\"IsA,animal\", True, \"IsA,candy\", False))\n",
        "print(check_constraints(\"IsA,animal\", False, \"IsA,candy\", True))\n",
        "print(check_constraints(\"IsA,animal\", False, \"IsA,candy\", False))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(False, False, False)\n(False, False, False)\n(False, False, False)\n(False, False, False)\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1647097063050
        }
      },
      "id": "526892fc-dcbc-4010-88a6-52ce2933ac8b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load models"
      ],
      "metadata": {},
      "id": "716ad53a-5ebc-4366-916e-534c78d69f44"
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1647097063265
        }
      },
      "id": "f2dd540c-0d05-4fec-85cc-6309b64a4764"
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloads a pretty large model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/macaw-large\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/macaw-large\")\n",
        "model = model.to(device=device).eval()"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1647097076787
        }
      },
      "id": "699dba1b-3171-4690-be58-a5fd082e80d8"
    },
    {
      "cell_type": "code",
      "source": [
        "# QA Model stuff\n",
        "def format_question(question_list):\n",
        "    question_list = [\"$answer$ ; $mcoptions$ = (A) yes (B) no; $question$ = \" + item \\\n",
        "         for item in question_list]\n",
        "    return question_list\n",
        "\n",
        "def predict(question_list, max_bsize=10):\n",
        "    B = len(question_list)\n",
        "    question_list = format_question(question_list)\n",
        "    answer_list_all_yes = [\"$answer$ = yes\"] * B     # pass in list of \"yes\"\n",
        "    \n",
        "    answers_all = []\n",
        "    confidences_all = []\n",
        "    for i in range(0, B, max_bsize):\n",
        "        j = min(i + max_bsize, B)\n",
        "        # print(dir(tokenizer))\n",
        "        inputs = tokenizer.batch_encode_plus(question_list[i:j], max_length = 256, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        labels = tokenizer.batch_encode_plus(answer_list_all_yes[i:j], max_length = 15, padding=True, truncation=True, return_tensors=\"pt\") # max_length is set to len(\"$answer$ = yes\")\n",
        "\n",
        "        # output = model.generate(input_ids, max_length=200)\n",
        "        # answers = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
        "        fwd = model(input_ids=inputs[\"input_ids\"].to(device), attention_mask=inputs[\"attention_mask\"].to(device),\n",
        "                    labels=labels[\"input_ids\"].to(device))\n",
        "                    # decoder_input_ids=labels[\"input_ids\"], decoder_attention_mask=labels[\"attention_mask\"])\n",
        "        # output_ids = torch.argmax(fwd.logits, dim=-1)\n",
        "        # print(tokenizer.batch_decode(output_ids, skip_special_tokens=True))\n",
        "\n",
        "        # loss\n",
        "        # loss = fwd.loss # - log(P(y|x))\n",
        "        # confidence = torch.exp(-loss)\n",
        "        logits = fwd.logits.reshape((j - i, 7, -1))\n",
        "        logits = logits[:, 5, :] # Index of yes/no token in answer\n",
        "        probs = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
        "        # yes has input_id 4273, no has input_id 150\n",
        "        confidence_yes = probs[..., 4273] \n",
        "        confidence_no = probs[..., 150]\n",
        "\n",
        "        answers = (confidence_yes >= confidence_no) # np.array([(ans == \"$answer$ = yes\") for ans in answers])\n",
        "        confidences = np.where(answers, confidence_yes, confidence_no)\n",
        "        answers_all.append(answers)\n",
        "        confidences_all.append(confidences)\n",
        "    answers = np.concatenate(answers_all, axis=0)\n",
        "    confidences = np.concatenate(confidences_all, axis=0)\n",
        "    return answers, confidences\n"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1647097077000
        }
      },
      "id": "d5f170c9-5046-4905-b309-e7a821357467"
    },
    {
      "cell_type": "code",
      "source": [
        "nli_tokenizer = AutoTokenizer.from_pretrained(\"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\")\n",
        "nli_model = AutoModelForSequenceClassification.from_pretrained(\"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\")\n",
        "nli_model = nli_model.to(device=device).eval()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of the model checkpoint at ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1647097081406
        }
      },
      "id": "59effc47-e588-4c7b-8e90-82bf14a9e4f4"
    },
    {
      "cell_type": "code",
      "source": [
        "def nli(sents, nli_tokenizer, nli_model, max_bsize=20):\n",
        "    \"\"\"Generates contradiction matrix of shape (N, B, B)\"\"\"\n",
        "    if sents.ndim == 1:\n",
        "        sents = sents.reshape(1, -1)\n",
        "    \n",
        "    N, B = sents.shape\n",
        "    prem = []\n",
        "    hypo = []\n",
        "    for i in range(N):\n",
        "        for j in range(B):\n",
        "            for k in range(B):\n",
        "                prem.append(sents[i][j])\n",
        "                hypo.append(sents[i][k])\n",
        "\n",
        "    nli_matrix = []\n",
        "    size = N * B * B\n",
        "    for i in range(0, size, max_bsize):\n",
        "        j = min(i + max_bsize, size)\n",
        "        tokenized = nli_tokenizer(prem[i:j], hypo[i:j], \n",
        "                                  max_length=256, \n",
        "                                  return_token_type_ids=True, \n",
        "                                  truncation=True,\n",
        "                                  padding=True)\n",
        "\n",
        "        input_ids = torch.Tensor(tokenized['input_ids']).to(device).long()\n",
        "        token_type_ids = torch.Tensor(tokenized['token_type_ids']).to(device).long()\n",
        "        attention_mask = torch.Tensor(tokenized['attention_mask']).to(device).long()\n",
        "\n",
        "        nli_outputs = nli_model(input_ids,\n",
        "                                attention_mask=attention_mask,\n",
        "                                token_type_ids=token_type_ids,\n",
        "                                labels=None)\n",
        "        nli_matrix.append(torch.softmax(nli_outputs.logits.detach().cpu(), dim=1))\n",
        "    nli_matrix = torch.cat(nli_matrix, dim=0)\n",
        "    nli_matrix = nli_matrix.reshape(N, B, B, 3)\n",
        "    return nli_matrix.numpy()\n",
        "\n",
        "# TODO: Mimic nli model, but using constraints graph\n",
        "def nli_constraints(big_batch, N, B):\n",
        "    nli_matrix = np.zeros((N, B, B, 3))\n",
        "    pass"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1647097081599
        }
      },
      "id": "1970157b-6933-4d87-b772-300891b1b457"
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(predictions, answers, pred_batch):\n",
        "    if predictions.ndim == 1:\n",
        "        predictions = predictions.reshape(1, -1)\n",
        "    answers = answers.reshape(predictions.shape)\n",
        "    relations = np.array([rel for ent, rel, pred in pred_batch]).reshape(predictions.shape)\n",
        "    N, B = predictions.shape\n",
        "    # predictions, answers, relations should be size (N, B)\n",
        "    \n",
        "    # Calculate accurate examples\n",
        "    correct = (predictions == answers)\n",
        "    acc = np.sum(correct)\n",
        "    \n",
        "    # Calculate metrics for F1\n",
        "    TP = np.sum(correct * answers)\n",
        "    TN = acc - TP\n",
        "    FN = np.sum((1 - correct) * answers)\n",
        "    FP = np.sum((1 - correct) * (1 - answers))\n",
        "    \n",
        "    # Calculate contradictions\n",
        "    con = 0\n",
        "    conacc = 0\n",
        "    relevant = 0 # Number of pairs that imply or contradict each other\n",
        "    for i in range(N):\n",
        "        for j in range(B):\n",
        "            for k in range(j+1, B):\n",
        "                impl12, impl21, contra = check_constraints( \\\n",
        "                    relations[i, j], predictions[i, j], relations[i, k], predictions[i, k])\n",
        "                if impl12 or impl21 or contra:\n",
        "                    relevant += 1\n",
        "                if contra:\n",
        "                    con += 1\n",
        "                else:\n",
        "                    conacc += (correct[i, j] and correct[i, k])\n",
        "    \n",
        "    total = predictions.size\n",
        "    bsize = predictions.shape[0]\n",
        "    return {\n",
        "        \"accurate\": acc,\n",
        "        \"TP\": TP,\n",
        "        \"TN\": TN,\n",
        "        \"FN\": FN,\n",
        "        \"FP\": FP,\n",
        "        \"contradictory_pairs\": con,\n",
        "        \"consistent_acc_pairs\": conacc,\n",
        "        \"relevant_pairs\": relevant,\n",
        "        \"total_questions\": predictions.size,\n",
        "        \"num_batches\": bsize,\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1647097081802
        }
      },
      "id": "9566f12a-18af-4d2a-a705-b56d55ca9f26"
    },
    {
      "cell_type": "code",
      "source": [
        "def counts_tostr(counts, i):\n",
        "    lines = []\n",
        "    N = counts[\"num_batches\"][i]\n",
        "    total = counts[\"total_questions\"][i]\n",
        "    B = total // N\n",
        "    total_pairs = N * B * (B - 1) // 2 # pairs per batch\n",
        "    accurate = counts['accurate'][i]\n",
        "    contradictions = counts['contradictory_pairs'][i]\n",
        "    relevant = counts['relevant_pairs'][i]\n",
        "    con_acc = counts['consistent_acc_pairs'][i]\n",
        "    flips = counts['flips'][i]\n",
        "    TP = counts['TP'][i]\n",
        "    FP = counts['FP'][i]\n",
        "    FN = counts['FN'][i]\n",
        "    precision = TP / (TP + FP)\n",
        "    recall = TP / (TP + FN)\n",
        "    f1 = 0 if precision == 0 and recall == 0 else 2 * precision * recall / (precision + recall)\n",
        "    lines.append(f\"Accurate {accurate} / {total} = {accurate / total}\")\n",
        "    lines.append(f\"Precision {precision}, recall {recall} ==> F1 {f1}\")\n",
        "    lines.append(f\"Contradictions {contradictions} / {total_pairs} pairs = {contradictions / total_pairs}\")\n",
        "    lines.append(f\"Contradictions {contradictions} / {relevant} relevant pairs = {contradictions / relevant}\")\n",
        "    lines.append(f\"Consistent+Accurate {con_acc} / {total_pairs} pairs = {con_acc / total_pairs}\")\n",
        "    lines.append(f\"Corrections {flips} / {N} batches = {flips / N}\")\n",
        "    return \"\\n\".join(lines)"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1647097082001
        }
      },
      "id": "e007a148-9d3a-4e20-9b65-abbc38d3c9b1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sampling methods\n",
        "1. base fact -> relation(s) on graph (must be downstream, or upstream if false)\n",
        "    Pro: Facts are close together\n",
        "    Con: Limited to guaranteed relations, so asymmetric\n",
        "2. base fact -> sample given facts that are nearby (not necessarily downstream)\n",
        "    Pro: Symmetric since all facts are given, facts are close together\n",
        "    Con: Contradictions may be a bit dense\n",
        "3. sample facts randomly (then just check afterwards)\n",
        "    Pro: Symmetric since all facts are given, sparser contradictions\n",
        "    Con: Facts may be distant, and constraints aren't complete, so will miss some constraints"
      ],
      "metadata": {},
      "id": "7ce59221-7942-4c06-9573-7bbe274c8da0"
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict([\"Is a buffalo a mammal?\", \"Is a buffalo not a mammal?\"], max_bsize=20))  # QA Model\n",
        "print(predict([\"Is a buffalo a water animal?\", \"Is a buffalo not a water animal?\"], max_bsize=20))  # QA Model\n",
        "generate_inverse_question(\"buffalo\", \"IsA,mammal\", \"true\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(array([ True, False]), array([0.9846942, 0.9998914], dtype=float32))\n(array([ True, False]), array([0.92805856, 0.9997551 ], dtype=float32))\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "('Is a buffalo not a mammal?', 'Yes')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1647097082220
        }
      },
      "id": "df5538a5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QA Requerying"
      ],
      "metadata": {},
      "id": "fdc5ada2"
    },
    {
      "cell_type": "code",
      "source": [
        "def requery_with_context(old_predictions, old_confidences, questions, nli_matrix, big_batch, return_flip_mask=False):\n",
        "    contra_matrix = nli_matrix[:, :, :, 2]\n",
        "    contra_matrix = (contra_matrix + contra_matrix.transpose((0, 2, 1))) / 2\n",
        "    contra_matrix[:, range(B), range(B)] = 0 # Set diagonals to 0\n",
        "\n",
        "    big_batch = np.array(big_batch).reshape(N,B,3) # (entity, rel, label) in last axis\n",
        "    questions = np.array(questions).reshape(N,B)\n",
        "     \n",
        "    correction_fn = getattr(correction_utils, 'C_1') # Apply C_1 correction function first\n",
        "    corrected, flip = correction_fn(old_predictions, old_confidences, nli_matrix, return_flip_mask=True)\n",
        "    \n",
        "    # For each elem in big_batch that should be flipped, invert question (answer remains same)\n",
        "    big_batch[:, :, 2] = np.logical_xor(big_batch[:, :, 2] == \"True\", flip) # Note: big_batch is modified\n",
        "    # Current answer | Flip? -> New Answer (XOR)\n",
        "    # 0 1 -> 1\n",
        "    # 0 0 -> 0\n",
        "    # 1 0 -> 1\n",
        "    # 1 1 -> 0\n",
        "\n",
        "    # Requery QA model with context if flipped\n",
        "    \n",
        "    new_predictions = np.zeros(old_predictions.shape)\n",
        "    new_confidences = np.zeros(old_confidences.shape)\n",
        "    for ij in np.ndindex(big_batch.shape[:2]): # convert to orig big_batch format\n",
        "        entity, relation, flipped = tuple(big_batch[ij])\n",
        "        \n",
        "        if(flipped): # flipped\n",
        "            print(\"Target tuple:\", tuple(big_batch[ij]))\n",
        "            requeried_questions = []\n",
        "            #go through list of other relations to find contradictory ones\n",
        "            for relation2 in range(B): \n",
        "                second_relation = big_batch[(ij[0], relation2)]\n",
        "                #if the statement is contradictory with our target\n",
        "\n",
        "                requeried_questions.append(generate_question_with_context(second_relation[0], second_relation[1], second_relation[2], big_batch[ij][0], big_batch[ij][1], big_batch[ij][2]))\n",
        "            print(requeried_questions)\n",
        "            total = 0\n",
        "            totalContradictions = 0\n",
        "            print(\"Iterating through predictions now\")\n",
        "            for relation2 in range(B):\n",
        "                if (contra_matrix[ij[0], ij[1], relation2] >= 0.5):\n",
        "                    totalContradictions += 1\n",
        "                    total += new_confidences[ij[0]][relation2]\n",
        "            new_confidences[ij] = total/totalContradictions\n",
        "            print(new_confidences[ij])\n",
        "    print(new_confidences)\n",
        "    input()\n",
        "    new_predictions = np.where(new_confidences > old_confidences, np.logical_not(old_predictions), old_predictions)\n",
        "    print(new_predictions.shape)\n",
        "    print(new_predictions)\n",
        "    changed_predictions = np.logical_xor(new_predictions, old_predictions)\n",
        "    corrected = new_predictions.copy()\n",
        "    flip = np.logical_xor(corrected, old_predictions)\n",
        "    if return_flip_mask:\n",
        "        return corrected, flip\n",
        "    return corrected\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1647097822194
        }
      },
      "id": "c8baf725"
    },
    {
      "cell_type": "code",
      "source": [
        "### Re-querying NLI/QA models\n",
        "# Patrick Liu the goat's sage advice:\n",
        "'''\n",
        "If A and B contradict, and you decide to flip B, then you have the same batch but with ~B\n",
        "Get the NLI with ~B (not entire matrix, just corresponding row/col -- compare ~B with the rest of batch)\n",
        "Then, if it contradicts with anything else in the batch, repeat\n",
        "'''\n",
        "\n",
        "def requery_inverted(old_predictions, old_confidences, questions, nli_matrix, big_batch, return_flip_mask=False):\n",
        "    big_batch = np.array(big_batch).reshape(N,B,3) # (entity, rel, label) in last axis\n",
        "    questions = np.array(questions).reshape(N,B)\n",
        "\n",
        "    correction_fn = getattr(correction_utils, 'C_1') # Apply C_1 correction function first\n",
        "    corrected, flip = correction_fn(old_predictions, old_confidences, nli_matrix, return_flip_mask=True)\n",
        " \n",
        "\n",
        "    # For each elem in big_batch that should be flipped, invert question (answer remains same)\n",
        "    big_batch[:, :, 2] = np.logical_xor(big_batch[:, :, 2] == \"True\", flip) # Note: big_batch is modified\n",
        "    # Current answer | Flip? -> New Answer (XOR)\n",
        "    # 0 1 -> 1\n",
        "    # 0 0 -> 0\n",
        "    # 1 0 -> 1\n",
        "    # 1 1 -> 0\n",
        "\n",
        "    # Requery QA model with inverted question if flipped\n",
        "    requeried_questions = []\n",
        "    for ij in np.ndindex(big_batch.shape[:2]): # convert to orig big_batch format\n",
        "        entity, relation, flipped = tuple(big_batch[ij])\n",
        "        print(entity, relation, flipped)\n",
        "        if(flipped): # flipped\n",
        "            new_q, _ = generate_inverse_question(entity, relation, flipped)\n",
        "        else: \n",
        "            new_q, _ = generate_question(entity, relation, flipped)\n",
        "        requeried_questions.append(new_q)\n",
        "    \n",
        "    new_predictions, new_confidences = predict(requeried_questions, max_bsize=20) # QA Model\n",
        "    new_predictions = new_predictions.reshape(N,B)\n",
        "    new_confidences = new_confidences.reshape(N,B)\n",
        "    changed_predictions = np.logical_xor(new_predictions, old_predictions) # Predictions that have changed with requery\n",
        "    # print(\"Predictions that have changed with QA requery: \" + changed_predictions)\n",
        "    # print(new_confidences, old_confidences, new_predictions, old_predictions)\n",
        "\n",
        "    # Take the prediction with the higher confidence score\n",
        "    combined_max_predictions = np.where(new_confidences > old_confidences, new_predictions, old_predictions)\n",
        "    # print(combined_max_confidences)\n",
        "\n",
        "    # Output stage\n",
        "    corrected = combined_max_predictions.copy()\n",
        "    flip = np.logical_xor(corrected, old_predictions)\n",
        "    if return_flip_mask:\n",
        "        return corrected, flip\n",
        "    return corrected\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1647097082607
        }
      },
      "id": "0e250974"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QA Requerying Eval"
      ],
      "metadata": {},
      "id": "53b32e47"
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "# correction_fn_names = ['C_0', 'C_1', 'C_2', 'C_3', 'C_4', 'C_5', 'C_6', 'C_7', 'C_8']\n",
        "correction_fn_names = ['C_0', 'C_1']\n",
        "correction_fns = [getattr(correction_utils, fn_name) for fn_name in correction_fn_names]\n",
        "\n",
        "\n",
        "counts = { \n",
        "    k: np.zeros(len(correction_fns), dtype=int) \n",
        "    for k in [\n",
        "        \"accurate\", \"TP\", \"TN\", \"FN\", \"FP\", \"contradictory_pairs\", \"consistent_acc_pairs\", \n",
        "        \"relevant_pairs\", \"total_questions\", \"num_batches\", \"flips\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "N = 10 # Number of entities to sample in a big batch\n",
        "batch_counter = 0\n",
        "num_batches = 0\n",
        "num_big_batches = 0\n",
        "big_batch = []\n",
        "\n",
        "B = 10 # Number of facts for each entity\n",
        "random.shuffle(dev_entities)\n",
        "idx_count = 0\n",
        "idx = 0\n",
        "while num_batches < 10:\n",
        "    if idx == len(dev_entities):\n",
        "        random.shuffle(dev_entities)\n",
        "        idx = 0\n",
        "    entity = dev_entities[idx]\n",
        "    idx += 1\n",
        "    idx_count += 1\n",
        "    \n",
        "    # Sample set of facts for an entity\n",
        "    # Sampling method 2\n",
        "    entity_facts = list(facts[entity].items())\n",
        "    base = random.choice(entity_facts)\n",
        "    relation, label = base\n",
        "    nearby = neighbors.get(relation, set())\n",
        "    allowed_facts = [f for f in entity_facts if f[0] in nearby]\n",
        "    if len(allowed_facts) < B - 1:\n",
        "        continue\n",
        "    batch = random.sample(allowed_facts, min(B - 1, len(allowed_facts)))\n",
        "    batch = [base] + batch\n",
        "    batch = [(entity, rel, label == \"yes\") for rel, label in batch]\n",
        "    \n",
        "\n",
        "    # # Random sampling (method 3)\n",
        "    # batch = random.sample(list(facts[entity].items()), B)\n",
        "    # batch = [(entity, relation, true == \"yes\") for relation, yes in batch]\n",
        "    \n",
        "    # Collect batches in big batches\n",
        "    if batch_counter == 0:\n",
        "        big_batch = []\n",
        "    batch_counter += 1\n",
        "    big_batch.extend(batch)\n",
        "    if batch_counter < N: # Big batch not full yet, keep accumulating examples\n",
        "        continue\n",
        "    # We have a full batch\n",
        "    batch_counter = 0\n",
        "    num_batches += N\n",
        "    num_big_batches += 1\n",
        "    \n",
        "    questions, answers = zip(*[generate_question(*tup) for tup in big_batch])\n",
        "    questions = list(questions)\n",
        "    answers = np.array(answers) == \"Yes\"\n",
        "    # print(\"Questions:\", questions)\n",
        "    # print(\"Labels (for contradiction):\", answers)\n",
        "    \n",
        "    predictions, confidences = predict(questions, max_bsize=20)\n",
        "    predictions = predictions.flatten()\n",
        "    confidences = confidences.flatten()\n",
        "    # print(\"QA predictions:\", predictions)\n",
        "    # print(\"QA confidences:\", confidences)\n",
        "    \n",
        "    pred_batch = [(ent, rel, predictions[i]) for i, (ent, rel, true) in enumerate(big_batch)]\n",
        "    assertions = [generate_assertion(*tup) for tup in pred_batch]\n",
        "    #print(\"Assertions:\", assertions)\n",
        "    \n",
        "    assertions = np.array(assertions).reshape(N, B)\n",
        "    nli_matrix = nli(assertions, nli_tokenizer, nli_model, max_bsize=20)\n",
        "    # print(\"NLI probability matrix:\\n\", nli_matrix)\n",
        "    \n",
        "    predictions = predictions.reshape(N, B)\n",
        "    confidences = confidences.reshape(N, B)\n",
        "\n",
        "    ### Evaluate with NLI Requeryingin enumerate(_fn_names):\n",
        "    \n",
        "    \n",
        "    corrected, flip_mask = requery_with_context(predictions.copy(), confidences.copy(), questions.copy(), nli_matrix.copy(), big_batch.copy(), return_flip_mask = True)\n",
        "\n",
        "    eval_dict = evaluate(corrected, answers, pred_batch)\n",
        "    \n",
        "    \n",
        "    \n",
        "    input()\n",
        "\n",
        "    ### Evaluate with correction functions\n",
        "    for i, correction_fn in enumerate(correction_fns):\n",
        "        corrected, flip_mask = correction_fn(predictions.copy(), confidences.copy(), nli_matrix.copy(), return_flip_mask=True)\n",
        "        counts['flips'][i] += np.count_nonzero(flip_mask)\n",
        "        eval_dict = evaluate(corrected, answers, pred_batch)\n",
        "        for k, v in eval_dict.items():\n",
        "            counts[k][i] += v\n",
        "    # print(eval_dict)\n",
        "    \n",
        "    if num_batches % 100 == 0:\n",
        "        print(f\"Iter {idx_count}: {num_batches} batches, {counts['total_questions'][0]} questions\")\n",
        "        for i, fn_name in enumerate(correction_fn_names):\n",
        "            print(f\"Correction function {fn_name}:\")\n",
        "            print('\\t' + counts_tostr(counts, i).replace('\\n', '\\n\\t'))\n",
        "            \n",
        "print(\"\\n==================== Final Results ====================\")\n",
        "print(f\"End on iter {idx_count}: {num_batches} {B}x{B} batches, {counts['total_questions'][0]} questions\")\n",
        "for i, fn_name in enumerate(correction_fn_names):\n",
        "    print(f\"Correction function {fn_name}:\")\n",
        "    print('\\t' + counts_tostr(counts, i).replace('\\n', '\\n\\t'))\n",
        "\n",
        "end = time.time()\n",
        "print(\"Runtime:\", end - start)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "IsA river  a   a  No\nIsA door  a   a  No\nIsA structure  a   a  No\nIsA turtle  a   a  No\nIsA palm tree  a   a  No\nIsA soup  a   a  No\nIsA president  a   a  No\nIsA doctor  a   a  No\nIsA publication  a   a  No\nIsA reptile  a   a  No\nIsA plant  a   a  No\nIsA government  a   a  No\nIsA computer  a   a  No\nIsA snake  a   a  No\nIsA president  a   a  No\nIsA building  a   a  No\nIsA flower  a   a  No\nIsA kitchen  a   a  No\nIsA jellyfish  a   a  No\nIsA tree  a   a  No\nIsA action  a   an  No\nIsA soup  a   a  No\nIsA rodent  a   a  No\nIsA food  a   a  No\nIsA acid  a   an  No\nIsA bacterium  a   a  No\nIsA herb  a   an  No\nIsA crustacean  a   a  No\nIsA house  a   a  No\nIsA plant  a   a  No\nIsA horse  a   a  No\nIsA publication  a   a  No\nIsA cat  a   a  No\nIsA river  a   a  No\nIsA religion  a   a  No\nIsA cheese  a   a  No\nIsA reptile  a   a  No\nIsA house  a   a  No\nIsA protein  a   a  No\nIsA machine  a   a  No\nIsA vehicle  a   a  No\nIsA mammal  a   a  No\nIsA virus  a   a  No\nIsA sport  a   a  No\nIsA artifact  a   an  No\nIsA building  a   a  No\nIsA machine  a   a  No\nIsA door  a   a  No\nIsA carbohydrate  a   a  No\nIsA horse  a   a  No\nIsA lizard  a   a  No\nIsA mineral  a   a  No\nIsA rodent  a   a  No\nIsA art  a   an  No\nIsA living creature  a   a  Yes\nIsA leader  a   a  No\nIsA animal  a   an  Yes\nIsA river  a   a  No\nIsA jellyfish  a   a  No\nIsA organism  a   an  Yes\nIsA body of water  a   a  No\nIsA city  a   a  No\nIsA river  a   a  No\nIsA town  a   a  No\nIsA europe  a   a  No\nIsA africa  a   an  No\nIsA continent  a   a  No\nIsA lake  a   a  No\nIsA planet  a   a  No\nIsA country  a   a  No\nIsA building  a   a  No\nIsA vertebrate  a   a  Yes\nIsA jewelry  a   a  No\nIsA structure  a   a  No\nIsA plastic  a   a  No\nIsA crustacean  a   a  No\nIsA company  a   a  No\nIsA sport  a   a  No\nIsA mineral  a   a  No\nIsA toy  a   a  No\nIsA turtle  a   a  No\nIsA car  a   a  No\nIsA shop  a   a  No\nIsA action  a   an  No\nIsA bathroom  a   a  No\nIsA fire  a   a  No\nIsA hair  a   a  No\nIsA religion  a   a  No\nIsA cat  a   a  No\nIsA boat  a   a  No\nCapableOf live  a   a  Yes\nIsA doctor  a   a  No\nIsA horse  a   a  No\nIsA invertebrate  a   an  No\nIsA expert  a   an  No\nIsA animal  a   an  Yes\nIsA vertebrate  a   a  Yes\nIsA deer  a   a  No\nIsA reptile  a   a  No\nIsA politician  a   a  No\nlamb IsA,river False\nlamb IsA,door True\nlamb IsA,structure True\nlamb IsA,turtle False\nlamb IsA,palm tree False\nlamb IsA,soup False\nlamb IsA,president False\nlamb IsA,doctor False\nlamb IsA,publication True\nlamb IsA,reptile False\nbaboon IsA,plant False\nbaboon IsA,government False\nbaboon IsA,computer False\nbaboon IsA,snake False\nbaboon IsA,president False\nbaboon IsA,building False\nbaboon IsA,flower False\nbaboon IsA,kitchen False\nbaboon IsA,jellyfish False\nbaboon IsA,tree False\ncrocodile IsA,action True\ncrocodile IsA,soup False\ncrocodile IsA,rodent False\ncrocodile IsA,food True\ncrocodile IsA,acid False\ncrocodile IsA,bacterium False\ncrocodile IsA,herb False\ncrocodile IsA,crustacean False\ncrocodile IsA,house False\ncrocodile IsA,plant False\nstarling IsA,horse False\nstarling IsA,publication True\nstarling IsA,cat False\nstarling IsA,river False\nstarling IsA,religion False\nstarling IsA,cheese False\nstarling IsA,reptile False\nstarling IsA,house False\nstarling IsA,protein True\nstarling IsA,machine False\nmagpie IsA,vehicle False\nmagpie IsA,mammal False\nmagpie IsA,virus False\nmagpie IsA,sport False\nmagpie IsA,artifact True\nmagpie IsA,building False\nmagpie IsA,machine False\nmagpie IsA,door False\nmagpie IsA,carbohydrate False\nmagpie IsA,horse False\nfoxhound IsA,lizard False\nfoxhound IsA,mineral False\nfoxhound IsA,rodent False\nfoxhound IsA,art False\nfoxhound IsA,living creature True\nfoxhound IsA,leader True\nfoxhound IsA,animal True\nfoxhound IsA,river False\nfoxhound IsA,jellyfish False\nfoxhound IsA,organism True\ncheetah IsA,body of water True\ncheetah IsA,city False\ncheetah IsA,river False\ncheetah IsA,town False\ncheetah IsA,europe False\ncheetah IsA,africa True\ncheetah IsA,continent False\ncheetah IsA,lake False\ncheetah IsA,planet False\ncheetah IsA,country False\nhummingbird IsA,building False\nhummingbird IsA,vertebrate True\nhummingbird IsA,jewelry False\nhummingbird IsA,structure True\nhummingbird IsA,plastic False\nhummingbird IsA,crustacean False\nhummingbird IsA,company False\nhummingbird IsA,sport False\nhummingbird IsA,mineral False\nhummingbird IsA,toy False\npeony IsA,turtle False\npeony IsA,car False\npeony IsA,shop False\npeony IsA,action True\npeony IsA,bathroom False\npeony IsA,fire False\npeony IsA,hair False\npeony IsA,religion False\npeony IsA,cat False\npeony IsA,boat False\ncock CapableOf,live True\ncock IsA,doctor False\ncock IsA,horse False\ncock IsA,invertebrate False\ncock IsA,expert True\ncock IsA,animal True\ncock IsA,vertebrate True\ncock IsA,deer False\ncock IsA,reptile False\ncock IsA,politician False\nTarget tuple: ('lamb', 'IsA,river', 'False')\nSecond relation ['lamb' 'IsA,river' 'False']\nVALUES: lamb IsA,river False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,river False\nSecond relation ['lamb' 'IsA,door' 'True']\nVALUES: lamb IsA,door True lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,door True\nSecond relation ['lamb' 'IsA,structure' 'False']\nVALUES: lamb IsA,structure False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,structure False\nSecond relation ['lamb' 'IsA,turtle' 'False']\nVALUES: lamb IsA,turtle False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,turtle False\nSecond relation ['lamb' 'IsA,palm tree' 'False']\nVALUES: lamb IsA,palm tree False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,palm tree False\nSecond relation ['lamb' 'IsA,soup' 'False']\nVALUES: lamb IsA,soup False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,soup False\nSecond relation ['lamb' 'IsA,president' 'False']\nVALUES: lamb IsA,president False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,president False\nSecond relation ['lamb' 'IsA,doctor' 'False']\nVALUES: lamb IsA,doctor False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,doctor False\nSecond relation ['lamb' 'IsA,publication' 'True']\nVALUES: lamb IsA,publication True lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,publication True\nSecond relation ['lamb' 'IsA,reptile' 'False']\nVALUES: lamb IsA,reptile False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,reptile False\n['A lamb is a river. Is a lamb a river?', 'A lamb is a door. Is a lamb a river?', 'A lamb is a structure. Is a lamb a river?', 'A lamb is a turtle. Is a lamb a river?', 'A lamb is a palm tree. Is a lamb a river?', 'A lamb is a soup. Is a lamb a river?', 'A lamb is a president. Is a lamb a river?', 'A lamb is a doctor. Is a lamb a river?', 'A lamb is a publication. Is a lamb a river?', 'A lamb is a reptile. Is a lamb a river?']\n[False False False False False False False False False False] [0.816021   0.9923563  0.6582199  0.99390125 0.9990138  0.90277386\n 0.96364415 0.9909123  0.54652613 0.9407088 ]\nTarget tuple: ('lamb', 'IsA,door', 'True')\nSecond relation ['lamb' 'IsA,river' 'False']\nVALUES: lamb IsA,river False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,river False\nSecond relation ['lamb' 'IsA,door' 'True']\nVALUES: lamb IsA,door True lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,door True\nSecond relation ['lamb' 'IsA,structure' 'False']\nVALUES: lamb IsA,structure False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,structure False\nSecond relation ['lamb' 'IsA,turtle' 'False']\nVALUES: lamb IsA,turtle False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,turtle False\nSecond relation ['lamb' 'IsA,palm tree' 'False']\nVALUES: lamb IsA,palm tree False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,palm tree False\nSecond relation ['lamb' 'IsA,soup' 'False']\nVALUES: lamb IsA,soup False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,soup False\nSecond relation ['lamb' 'IsA,president' 'False']\nVALUES: lamb IsA,president False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,president False\nSecond relation ['lamb' 'IsA,doctor' 'False']\nVALUES: lamb IsA,doctor False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,doctor False\nSecond relation ['lamb' 'IsA,publication' 'True']\nVALUES: lamb IsA,publication True lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,publication True\nSecond relation ['lamb' 'IsA,reptile' 'False']\nVALUES: lamb IsA,reptile False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,reptile False\n['A lamb is a river. Is a lamb a door?', 'A lamb is a door. Is a lamb a door?', 'A lamb is a structure. Is a lamb a door?', 'A lamb is a turtle. Is a lamb a door?', 'A lamb is a palm tree. Is a lamb a door?', 'A lamb is a soup. Is a lamb a door?', 'A lamb is a president. Is a lamb a door?', 'A lamb is a doctor. Is a lamb a door?', 'A lamb is a publication. Is a lamb a door?', 'A lamb is a reptile. Is a lamb a door?']\n[False  True  True False False False False False  True False] [0.84718585 0.73810273 0.9320725  0.99395    0.9910024  0.7335465\n 0.95467293 0.9885926  0.770424   0.72510856]\nTarget tuple: ('lamb', 'IsA,structure', 'False')\nSecond relation ['lamb' 'IsA,river' 'False']\nVALUES: lamb IsA,river False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,river False\nSecond relation ['lamb' 'IsA,door' 'True']\nVALUES: lamb IsA,door True lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,door True\nSecond relation ['lamb' 'IsA,structure' 'False']\nVALUES: lamb IsA,structure False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,structure False\nSecond relation ['lamb' 'IsA,turtle' 'False']\nVALUES: lamb IsA,turtle False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,turtle False\nSecond relation ['lamb' 'IsA,palm tree' 'False']\nVALUES: lamb IsA,palm tree False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,palm tree False\nSecond relation ['lamb' 'IsA,soup' 'False']\nVALUES: lamb IsA,soup False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,soup False\nSecond relation ['lamb' 'IsA,president' 'False']\nVALUES: lamb IsA,president False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,president False\nSecond relation ['lamb' 'IsA,doctor' 'False']\nVALUES: lamb IsA,doctor False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,doctor False\nSecond relation ['lamb' 'IsA,publication' 'True']\nVALUES: lamb IsA,publication True lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,publication True\nSecond relation ['lamb' 'IsA,reptile' 'False']\nVALUES: lamb IsA,reptile False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,reptile False\n['A lamb is a river. Is a lamb a structure?', 'A lamb is a door. Is a lamb a structure?', 'A lamb is a structure. Is a lamb a structure?', 'A lamb is a turtle. Is a lamb a structure?', 'A lamb is a palm tree. Is a lamb a structure?', 'A lamb is a soup. Is a lamb a structure?', 'A lamb is a president. Is a lamb a structure?', 'A lamb is a doctor. Is a lamb a structure?', 'A lamb is a publication. Is a lamb a structure?', 'A lamb is a reptile. Is a lamb a structure?']\n[False  True  True False False False False False  True False] [0.8330026  0.8332689  0.99933225 0.7822089  0.86342543 0.9861559\n 0.5165893  0.6167978  0.81952804 0.85408   ]\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1647094930089
        }
      },
      "id": "88143abe-885c-499c-bcfc-40304aa1edf1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other Evaluation Function Eval"
      ],
      "metadata": {},
      "id": "460c83c0"
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "# correction_fn_names = ['C_0', 'C_1', 'C_2', 'C_3', 'C_4', 'C_5', 'C_6', 'C_7', 'C_8']\n",
        "correction_fn_names = ['C_0', 'C_1']\n",
        "correction_fns = [getattr(correction_utils, fn_name) for fn_name in correction_fn_names]\n",
        "\n",
        "\n",
        "counts = { \n",
        "    k: np.zeros(len(correction_fns), dtype=int) \n",
        "    for k in [\n",
        "        \"accurate\", \"TP\", \"TN\", \"FN\", \"FP\", \"contradictory_pairs\", \"consistent_acc_pairs\", \n",
        "        \"relevant_pairs\", \"total_questions\", \"num_batches\", \"flips\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "N = 10 # Number of entities to sample in a big batch\n",
        "batch_counter = 0\n",
        "num_batches = 0\n",
        "num_big_batches = 0\n",
        "big_batch = []\n",
        "\n",
        "B = 10 # Number of facts for each entity\n",
        "random.shuffle(dev_entities)\n",
        "idx_count = 0\n",
        "idx = 0\n",
        "while num_batches < 10:\n",
        "    if idx == len(dev_entities):\n",
        "        random.shuffle(dev_entities)\n",
        "        idx = 0\n",
        "    entity = dev_entities[idx]\n",
        "    idx += 1\n",
        "    idx_count += 1\n",
        "    \n",
        "    # Sample set of facts for an entity\n",
        "    # Sampling method 2\n",
        "    entity_facts = list(facts[entity].items())\n",
        "    base = random.choice(entity_facts)\n",
        "    relation, label = base\n",
        "    nearby = neighbors.get(relation, set())\n",
        "    allowed_facts = [f for f in entity_facts if f[0] in nearby]\n",
        "    if len(allowed_facts) < B - 1:\n",
        "        continue\n",
        "    batch = random.sample(allowed_facts, min(B - 1, len(allowed_facts)))\n",
        "    batch = [base] + batch\n",
        "    batch = [(entity, rel, label == \"yes\") for rel, label in batch]\n",
        "    \n",
        "\n",
        "    # # Random sampling (method 3)\n",
        "    # batch = random.sample(list(facts[entity].items()), B)\n",
        "    # batch = [(entity, relation, true == \"yes\") for relation, yes in batch]\n",
        "    \n",
        "    # Collect batches in big batches\n",
        "    if batch_counter == 0:\n",
        "        big_batch = []\n",
        "    batch_counter += 1\n",
        "    big_batch.extend(batch)\n",
        "    if batch_counter < N: # Big batch not full yet, keep accumulating examples\n",
        "        continue\n",
        "    # We have a full batch\n",
        "    batch_counter = 0\n",
        "    num_batches += N\n",
        "    num_big_batches += 1\n",
        "    \n",
        "    questions, answers = zip(*[generate_question(*tup) for tup in big_batch])\n",
        "    questions = list(questions)\n",
        "    answers = np.array(answers) == \"Yes\"\n",
        "    # print(\"Questions:\", questions)\n",
        "    # print(\"Labels (for contradiction):\", answers)\n",
        "    \n",
        "    predictions, confidences = predict(questions, max_bsize=20)\n",
        "    predictions = predictions.flatten()\n",
        "    confidences = confidences.flatten()\n",
        "    # print(\"QA predictions:\", predictions)\n",
        "    # print(\"QA confidences:\", confidences)\n",
        "    \n",
        "    pred_batch = [(ent, rel, predictions[i]) for i, (ent, rel, true) in enumerate(big_batch)]\n",
        "    assertions = [generate_assertion(*tup) for tup in pred_batch]\n",
        "    #print(\"Assertions:\", assertions)\n",
        "    \n",
        "    assertions = np.array(assertions).reshape(N, B)\n",
        "    nli_matrix = nli(assertions, nli_tokenizer, nli_model, max_bsize=20)\n",
        "    # print(\"NLI probability matrix:\\n\", nli_matrix)\n",
        "    \n",
        "    predictions = predictions.reshape(N, B)\n",
        "    confidences = confidences.reshape(N, B)\n",
        "\n",
        "    ### Evaluate with NLI Requeryingin enumerate(_fn_names):\n",
        "    \n",
        "    \n",
        "    corrected, flip_mask = requery_with_context(predictions.copy(), confidences.copy(), questions.copy(), nli_matrix.copy(), big_batch.copy(), return_flip_mask = True)\n",
        "\n",
        "    eval_dict = evaluate(corrected, answers, pred_batch)\n",
        "    \n",
        "    \n",
        "    \n",
        "    input()\n",
        "\n",
        "    ### Evaluate with correction functions\n",
        "    for i, correction_fn in enumerate(correction_fns):\n",
        "        corrected, flip_mask = correction_fn(predictions.copy(), confidences.copy(), nli_matrix.copy(), return_flip_mask=True)\n",
        "        counts['flips'][i] += np.count_nonzero(flip_mask)\n",
        "        eval_dict = evaluate(corrected, answers, pred_batch)\n",
        "        for k, v in eval_dict.items():\n",
        "            counts[k][i] += v\n",
        "    # print(eval_dict)\n",
        "    \n",
        "    if num_batches % 100 == 0:\n",
        "        print(f\"Iter {idx_count}: {num_batches} batches, {counts['total_questions'][0]} questions\")\n",
        "        for i, fn_name in enumerate(correction_fn_names):\n",
        "            print(f\"Correction function {fn_name}:\")\n",
        "            print('\\t' + counts_tostr(counts, i).replace('\\n', '\\n\\t'))\n",
        "            \n",
        "print(\"\\n==================== Final Results ====================\")\n",
        "print(f\"End on iter {idx_count}: {num_batches} {B}x{B} batches, {counts['total_questions'][0]} questions\")\n",
        "for i, fn_name in enumerate(correction_fn_names):\n",
        "    print(f\"Correction function {fn_name}:\")\n",
        "    print('\\t' + counts_tostr(counts, i).replace('\\n', '\\n\\t'))\n",
        "\n",
        "end = time.time()\n",
        "print(\"Runtime:\", end - start)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "IsA river  a   a  No\nIsA door  a   a  No\nIsA structure  a   a  No\nIsA turtle  a   a  No\nIsA palm tree  a   a  No\nIsA soup  a   a  No\nIsA president  a   a  No\nIsA doctor  a   a  No\nIsA publication  a   a  No\nIsA reptile  a   a  No\nIsA plant  a   a  No\nIsA government  a   a  No\nIsA computer  a   a  No\nIsA snake  a   a  No\nIsA president  a   a  No\nIsA building  a   a  No\nIsA flower  a   a  No\nIsA kitchen  a   a  No\nIsA jellyfish  a   a  No\nIsA tree  a   a  No\nIsA action  a   an  No\nIsA soup  a   a  No\nIsA rodent  a   a  No\nIsA food  a   a  No\nIsA acid  a   an  No\nIsA bacterium  a   a  No\nIsA herb  a   an  No\nIsA crustacean  a   a  No\nIsA house  a   a  No\nIsA plant  a   a  No\nIsA horse  a   a  No\nIsA publication  a   a  No\nIsA cat  a   a  No\nIsA river  a   a  No\nIsA religion  a   a  No\nIsA cheese  a   a  No\nIsA reptile  a   a  No\nIsA house  a   a  No\nIsA protein  a   a  No\nIsA machine  a   a  No\nIsA vehicle  a   a  No\nIsA mammal  a   a  No\nIsA virus  a   a  No\nIsA sport  a   a  No\nIsA artifact  a   an  No\nIsA building  a   a  No\nIsA machine  a   a  No\nIsA door  a   a  No\nIsA carbohydrate  a   a  No\nIsA horse  a   a  No\nIsA lizard  a   a  No\nIsA mineral  a   a  No\nIsA rodent  a   a  No\nIsA art  a   an  No\nIsA living creature  a   a  Yes\nIsA leader  a   a  No\nIsA animal  a   an  Yes\nIsA river  a   a  No\nIsA jellyfish  a   a  No\nIsA organism  a   an  Yes\nIsA body of water  a   a  No\nIsA city  a   a  No\nIsA river  a   a  No\nIsA town  a   a  No\nIsA europe  a   a  No\nIsA africa  a   an  No\nIsA continent  a   a  No\nIsA lake  a   a  No\nIsA planet  a   a  No\nIsA country  a   a  No\nIsA building  a   a  No\nIsA vertebrate  a   a  Yes\nIsA jewelry  a   a  No\nIsA structure  a   a  No\nIsA plastic  a   a  No\nIsA crustacean  a   a  No\nIsA company  a   a  No\nIsA sport  a   a  No\nIsA mineral  a   a  No\nIsA toy  a   a  No\nIsA turtle  a   a  No\nIsA car  a   a  No\nIsA shop  a   a  No\nIsA action  a   an  No\nIsA bathroom  a   a  No\nIsA fire  a   a  No\nIsA hair  a   a  No\nIsA religion  a   a  No\nIsA cat  a   a  No\nIsA boat  a   a  No\nCapableOf live  a   a  Yes\nIsA doctor  a   a  No\nIsA horse  a   a  No\nIsA invertebrate  a   an  No\nIsA expert  a   an  No\nIsA animal  a   an  Yes\nIsA vertebrate  a   a  Yes\nIsA deer  a   a  No\nIsA reptile  a   a  No\nIsA politician  a   a  No\nlamb IsA,river False\nlamb IsA,door True\nlamb IsA,structure True\nlamb IsA,turtle False\nlamb IsA,palm tree False\nlamb IsA,soup False\nlamb IsA,president False\nlamb IsA,doctor False\nlamb IsA,publication True\nlamb IsA,reptile False\nbaboon IsA,plant False\nbaboon IsA,government False\nbaboon IsA,computer False\nbaboon IsA,snake False\nbaboon IsA,president False\nbaboon IsA,building False\nbaboon IsA,flower False\nbaboon IsA,kitchen False\nbaboon IsA,jellyfish False\nbaboon IsA,tree False\ncrocodile IsA,action True\ncrocodile IsA,soup False\ncrocodile IsA,rodent False\ncrocodile IsA,food True\ncrocodile IsA,acid False\ncrocodile IsA,bacterium False\ncrocodile IsA,herb False\ncrocodile IsA,crustacean False\ncrocodile IsA,house False\ncrocodile IsA,plant False\nstarling IsA,horse False\nstarling IsA,publication True\nstarling IsA,cat False\nstarling IsA,river False\nstarling IsA,religion False\nstarling IsA,cheese False\nstarling IsA,reptile False\nstarling IsA,house False\nstarling IsA,protein True\nstarling IsA,machine False\nmagpie IsA,vehicle False\nmagpie IsA,mammal False\nmagpie IsA,virus False\nmagpie IsA,sport False\nmagpie IsA,artifact True\nmagpie IsA,building False\nmagpie IsA,machine False\nmagpie IsA,door False\nmagpie IsA,carbohydrate False\nmagpie IsA,horse False\nfoxhound IsA,lizard False\nfoxhound IsA,mineral False\nfoxhound IsA,rodent False\nfoxhound IsA,art False\nfoxhound IsA,living creature True\nfoxhound IsA,leader True\nfoxhound IsA,animal True\nfoxhound IsA,river False\nfoxhound IsA,jellyfish False\nfoxhound IsA,organism True\ncheetah IsA,body of water True\ncheetah IsA,city False\ncheetah IsA,river False\ncheetah IsA,town False\ncheetah IsA,europe False\ncheetah IsA,africa True\ncheetah IsA,continent False\ncheetah IsA,lake False\ncheetah IsA,planet False\ncheetah IsA,country False\nhummingbird IsA,building False\nhummingbird IsA,vertebrate True\nhummingbird IsA,jewelry False\nhummingbird IsA,structure True\nhummingbird IsA,plastic False\nhummingbird IsA,crustacean False\nhummingbird IsA,company False\nhummingbird IsA,sport False\nhummingbird IsA,mineral False\nhummingbird IsA,toy False\npeony IsA,turtle False\npeony IsA,car False\npeony IsA,shop False\npeony IsA,action True\npeony IsA,bathroom False\npeony IsA,fire False\npeony IsA,hair False\npeony IsA,religion False\npeony IsA,cat False\npeony IsA,boat False\ncock CapableOf,live True\ncock IsA,doctor False\ncock IsA,horse False\ncock IsA,invertebrate False\ncock IsA,expert True\ncock IsA,animal True\ncock IsA,vertebrate True\ncock IsA,deer False\ncock IsA,reptile False\ncock IsA,politician False\nTarget tuple: ('lamb', 'IsA,river', 'False')\nSecond relation ['lamb' 'IsA,river' 'False']\nVALUES: lamb IsA,river False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,river False\nSecond relation ['lamb' 'IsA,door' 'True']\nVALUES: lamb IsA,door True lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,door True\nSecond relation ['lamb' 'IsA,structure' 'False']\nVALUES: lamb IsA,structure False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,structure False\nSecond relation ['lamb' 'IsA,turtle' 'False']\nVALUES: lamb IsA,turtle False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,turtle False\nSecond relation ['lamb' 'IsA,palm tree' 'False']\nVALUES: lamb IsA,palm tree False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,palm tree False\nSecond relation ['lamb' 'IsA,soup' 'False']\nVALUES: lamb IsA,soup False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,soup False\nSecond relation ['lamb' 'IsA,president' 'False']\nVALUES: lamb IsA,president False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,president False\nSecond relation ['lamb' 'IsA,doctor' 'False']\nVALUES: lamb IsA,doctor False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,doctor False\nSecond relation ['lamb' 'IsA,publication' 'True']\nVALUES: lamb IsA,publication True lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,publication True\nSecond relation ['lamb' 'IsA,reptile' 'False']\nVALUES: lamb IsA,reptile False lamb IsA,river False\nIsA river  a   a  Yes\nlamb IsA,reptile False\n['A lamb is a river. Is a lamb a river?', 'A lamb is a door. Is a lamb a river?', 'A lamb is a structure. Is a lamb a river?', 'A lamb is a turtle. Is a lamb a river?', 'A lamb is a palm tree. Is a lamb a river?', 'A lamb is a soup. Is a lamb a river?', 'A lamb is a president. Is a lamb a river?', 'A lamb is a doctor. Is a lamb a river?', 'A lamb is a publication. Is a lamb a river?', 'A lamb is a reptile. Is a lamb a river?']\n[False False False False False False False False False False] [0.816021   0.9923563  0.6582199  0.99390125 0.9990138  0.90277386\n 0.96364415 0.9909123  0.54652613 0.9407088 ]\nTarget tuple: ('lamb', 'IsA,door', 'True')\nSecond relation ['lamb' 'IsA,river' 'False']\nVALUES: lamb IsA,river False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,river False\nSecond relation ['lamb' 'IsA,door' 'True']\nVALUES: lamb IsA,door True lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,door True\nSecond relation ['lamb' 'IsA,structure' 'False']\nVALUES: lamb IsA,structure False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,structure False\nSecond relation ['lamb' 'IsA,turtle' 'False']\nVALUES: lamb IsA,turtle False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,turtle False\nSecond relation ['lamb' 'IsA,palm tree' 'False']\nVALUES: lamb IsA,palm tree False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,palm tree False\nSecond relation ['lamb' 'IsA,soup' 'False']\nVALUES: lamb IsA,soup False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,soup False\nSecond relation ['lamb' 'IsA,president' 'False']\nVALUES: lamb IsA,president False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,president False\nSecond relation ['lamb' 'IsA,doctor' 'False']\nVALUES: lamb IsA,doctor False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,doctor False\nSecond relation ['lamb' 'IsA,publication' 'True']\nVALUES: lamb IsA,publication True lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,publication True\nSecond relation ['lamb' 'IsA,reptile' 'False']\nVALUES: lamb IsA,reptile False lamb IsA,door True\nIsA door  a   a  Yes\nlamb IsA,reptile False\n['A lamb is a river. Is a lamb a door?', 'A lamb is a door. Is a lamb a door?', 'A lamb is a structure. Is a lamb a door?', 'A lamb is a turtle. Is a lamb a door?', 'A lamb is a palm tree. Is a lamb a door?', 'A lamb is a soup. Is a lamb a door?', 'A lamb is a president. Is a lamb a door?', 'A lamb is a doctor. Is a lamb a door?', 'A lamb is a publication. Is a lamb a door?', 'A lamb is a reptile. Is a lamb a door?']\n[False  True  True False False False False False  True False] [0.84718585 0.73810273 0.9320725  0.99395    0.9910024  0.7335465\n 0.95467293 0.9885926  0.770424   0.72510856]\nTarget tuple: ('lamb', 'IsA,structure', 'False')\nSecond relation ['lamb' 'IsA,river' 'False']\nVALUES: lamb IsA,river False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,river False\nSecond relation ['lamb' 'IsA,door' 'True']\nVALUES: lamb IsA,door True lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,door True\nSecond relation ['lamb' 'IsA,structure' 'False']\nVALUES: lamb IsA,structure False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,structure False\nSecond relation ['lamb' 'IsA,turtle' 'False']\nVALUES: lamb IsA,turtle False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,turtle False\nSecond relation ['lamb' 'IsA,palm tree' 'False']\nVALUES: lamb IsA,palm tree False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,palm tree False\nSecond relation ['lamb' 'IsA,soup' 'False']\nVALUES: lamb IsA,soup False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,soup False\nSecond relation ['lamb' 'IsA,president' 'False']\nVALUES: lamb IsA,president False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,president False\nSecond relation ['lamb' 'IsA,doctor' 'False']\nVALUES: lamb IsA,doctor False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,doctor False\nSecond relation ['lamb' 'IsA,publication' 'True']\nVALUES: lamb IsA,publication True lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,publication True\nSecond relation ['lamb' 'IsA,reptile' 'False']\nVALUES: lamb IsA,reptile False lamb IsA,structure False\nIsA structure  a   a  Yes\nlamb IsA,reptile False\n['A lamb is a river. Is a lamb a structure?', 'A lamb is a door. Is a lamb a structure?', 'A lamb is a structure. Is a lamb a structure?', 'A lamb is a turtle. Is a lamb a structure?', 'A lamb is a palm tree. Is a lamb a structure?', 'A lamb is a soup. Is a lamb a structure?', 'A lamb is a president. Is a lamb a structure?', 'A lamb is a doctor. Is a lamb a structure?', 'A lamb is a publication. Is a lamb a structure?', 'A lamb is a reptile. Is a lamb a structure?']\n[False  True  True False False False False False  True False] [0.8330026  0.8332689  0.99933225 0.7822089  0.86342543 0.9861559\n 0.5165893  0.6167978  0.81952804 0.85408   ]\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1647094930089
        }
      },
      "id": "88143abe-885c-499c-bcfc-40304aa1edf1"
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
        "print(now)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1647086152880
        }
      },
      "id": "d406c953-eab3-4d91-af3b-adfa2780528f"
    },
    {
      "cell_type": "code",
      "source": [
        "df_dict = counts.copy()\n",
        "df_dict['correction_fn'] = correction_fn_names\n",
        "df = pd.DataFrame(df_dict)\n",
        "df = df[['correction_fn'] + [k for k in counts.keys()]]\n",
        "df.to_csv(f'results/{now}.csv', index=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1647086154017
        }
      },
      "id": "3334bdb7-69e0-45b0-8778-b06c4aebd869"
    },
    {
      "cell_type": "code",
      "source": [
        "# now = \"2022-02-26T06:34:50\"\n",
        "df = pd.read_csv(f'results/{now}.csv')\n",
        "df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1647086155937
        }
      },
      "id": "42ba4e0b-ee37-4ce1-a7b1-78c0b7e0531a"
    },
    {
      "cell_type": "code",
      "source": [
        "correction_fn_names = df['correction_fn'].to_numpy()\n",
        "for k in df.columns:\n",
        "    if k == 'correction_fn':\n",
        "        continue\n",
        "    print(k)\n",
        "    exec(f\"{k} = df['{k}'].to_numpy()\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1647086157364
        }
      },
      "id": "47cc106a-acfc-4cef-8e91-7ee9eb0cec26"
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = accurate / total_questions * 100\n",
        "precisions = TP / (TP + FP)\n",
        "recalls = TP / (TP + FN)\n",
        "f1_scores = 2 * TP / (2 * TP + FP + FN)\n",
        "contra_rates = contradictory_pairs / (num_batches * B * (B - 1) / 2) * 100\n",
        "relevant_contra_rates = contradictory_pairs / relevant_pairs * 100\n",
        "conacc_rates = consistent_acc_pairs / (num_batches * B * (B - 1) / 2) * 100\n",
        "flip_rates = (flips / total_questions) * 100\n",
        "if not os.path.isdir(f\"figures/{now}\"):\n",
        "    os.mkdir(f\"figures/{now}\")\n",
        "\n",
        "figsize = (5,5)\n",
        "fig, ax = plt.subplots(figsize=figsize)\n",
        "ax.bar(correction_fn_names, accuracies)\n",
        "for i, v in enumerate(accuracies):\n",
        "    ax.text(i, v + 1 + max(accuracies) // 25, str(round(v, 1)), color=\"#0967a2\", fontweight='semibold', ha='center', va='center')\n",
        "ax.set_ylim(0, 100)\n",
        "ax.set_xlabel(\"Correction method\")\n",
        "ax.set_ylabel(\"Percent accuracy\")\n",
        "plt.show()\n",
        "fig.savefig(f\"figures/{now}/accuracy.png\")\n",
        "\n",
        "figsize = (5,5)\n",
        "fig, ax = plt.subplots(figsize=figsize)\n",
        "ax.bar(correction_fn_names, precisions)\n",
        "for i, v in enumerate(precisions):\n",
        "    ax.text(i, v + 0.02, str(round(v, 2)), color=\"#0967a2\", fontweight='semibold', ha='center', va='center')\n",
        "ax.set_ylim(0, min(max(precisions + 0.1), 1.05))\n",
        "ax.set_xlabel(\"Correction method\")\n",
        "ax.set_ylabel(\"Precision\")\n",
        "plt.show()\n",
        "fig.savefig(f\"figures/{now}/precision.png\")\n",
        "\n",
        "figsize = (5,5)\n",
        "fig, ax = plt.subplots(figsize=figsize)\n",
        "ax.bar(correction_fn_names, recalls)\n",
        "for i, v in enumerate(recalls):\n",
        "    ax.text(i, v + 0.05, str(round(v, 2)), color=\"#0967a2\", fontweight='semibold', ha='center', va='center')\n",
        "ax.set_ylim(0, min(max(recalls + 0.1), 1.05))\n",
        "ax.set_xlabel(\"Correction method\")\n",
        "ax.set_ylabel(\"Recall\")\n",
        "plt.show()\n",
        "fig.savefig(f\"figures/{now}/recall.png\")\n",
        "\n",
        "figsize = (5,5)\n",
        "fig, ax = plt.subplots(figsize=figsize)\n",
        "ax.bar(correction_fn_names, f1_scores)\n",
        "for i, v in enumerate(f1_scores):\n",
        "    ax.text(i, v + 0.02, str(round(v, 2)), color=\"#0967a2\", fontweight='semibold', ha='center', va='center')\n",
        "ax.set_ylim(0, min(max(f1_scores + 0.1), 1.05))\n",
        "ax.set_xlabel(\"Correction method\")\n",
        "ax.set_ylabel(\"F1 score\")\n",
        "plt.show()\n",
        "fig.savefig(f\"figures/{now}/f1_score.png\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=figsize)\n",
        "plt.bar(correction_fn_names, contra_rates)\n",
        "for i, v in enumerate(contra_rates):\n",
        "    ax.text(i, v + 1 + max(contra_rates) // 25, str(round(v, 1)), color=\"#0967a2\", fontweight='semibold', ha='center', va='center')\n",
        "ax.set_ylim(0, min(max(contra_rates) + 5, 100))\n",
        "ax.set_xlabel(\"Correction method\")\n",
        "ax.set_ylabel(\"Percent contradictory pairs\")\n",
        "plt.show()\n",
        "fig.savefig(f\"figures/{now}/contradict.png\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=figsize)\n",
        "plt.bar(correction_fn_names, relevant_contra_rates)\n",
        "for i, v in enumerate(relevant_contra_rates):\n",
        "    ax.text(i, v + 1 + max(relevant_contra_rates) // 25, str(round(v, 1)), color=\"#0967a2\", fontweight='semibold', ha='center', va='center')\n",
        "ax.set_ylim(0, min(max(relevant_contra_rates) + 5, 100))\n",
        "ax.set_xlabel(\"Correction method\")\n",
        "ax.set_ylabel(\"Percent contradictory relevant pairs\")\n",
        "plt.show()\n",
        "fig.savefig(f\"figures/{now}/contradict_relevant.png\") \n",
        "\n",
        "fig, ax = plt.subplots(figsize=figsize)\n",
        "plt.bar(correction_fn_names, conacc_rates)\n",
        "for i, v in enumerate(conacc_rates):\n",
        "    ax.text(i, v + 1 + max(accuracies) // 25, str(round(v, 1)), color=\"#0967a2\", fontweight='semibold', ha='center', va='center')\n",
        "ax.set_ylim(0, min(max(conacc_rates) + 10, 100))\n",
        "ax.set_xlabel(\"Correction method\")\n",
        "ax.set_ylabel(\"Percent consistent accuracy\")\n",
        "plt.show()\n",
        "fig.savefig(f\"figures/{now}/consistent_accuracy.png\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=figsize)\n",
        "plt.bar(correction_fn_names, flip_rates)\n",
        "for i, v in enumerate(flip_rates):\n",
        "    ax.text(i, v + 1 + max(accuracies) // 25, str(round(v, 1)), color=\"#0967a2\", fontweight='semibold', ha='center', va='center')\n",
        "ax.set_ylim(0, min(max(flip_rates) + 10, 100))\n",
        "ax.set_xlabel(\"Correction method\")\n",
        "ax.set_ylabel(\"Percent flipped predictions\")\n",
        "plt.show()\n",
        "fig.savefig(f\"figures/{now}/flipped.png\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1647086164468
        }
      },
      "id": "be471021-3425-4462-8644-5e43347b7669"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "4ca2bd2d-3125-4e00-b1c3-b33c6ee04aa0"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "1fb390e9"
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "9169f1d4e16acc976bbb73e323b0dbdf23f1c55e833fb2befffc4fb50ac2de2f"
    },
    "kernel_info": {
      "name": "azureml_py38_pt_tf"
    },
    "kernelspec": {
      "name": "azureml_py38_pt_tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}