{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# Macaw-large, PTLM \n",
    "# https://github.com/allenai/macaw\n",
    "# This was used in the BeliefBank Paper\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads a pretty large model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/macaw-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/macaw-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example output for a simple question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$answer$ = no']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string = \"$answer$ ; $mcoptions$ = (A) yes (B) no; $question$ = Is a robin a virus?\"\n",
    "input_ids = tokenizer.encode(input_string, return_tensors=\"pt\")\n",
    "output = model.generate(input_ids, max_length=200)\n",
    "\n",
    "tokenizer.batch_decode(output, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is an albatross a bird?|Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is an albatross a seabird?|Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is an albatross an animal?|Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is an albatross a eukaryotic_organism?|Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is an albatross a pelagic_bird?|Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>Is a daffodil a palm tree?|No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>Is a daffodil a crustacean?|No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>Is a daffodil a jellyfish?|No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>Is a daffodil an invertebrate?|No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>Is a daffodil a rodent?|No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1072 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0\n",
       "0                    Is an albatross a bird?|Yes\n",
       "1                 Is an albatross a seabird?|Yes\n",
       "2                 Is an albatross an animal?|Yes\n",
       "3     Is an albatross a eukaryotic_organism?|Yes\n",
       "4            Is an albatross a pelagic_bird?|Yes\n",
       "...                                          ...\n",
       "1067               Is a daffodil a palm tree?|No\n",
       "1068              Is a daffodil a crustacean?|No\n",
       "1069               Is a daffodil a jellyfish?|No\n",
       "1070           Is a daffodil an invertebrate?|No\n",
       "1071                  Is a daffodil a rodent?|No\n",
       "\n",
       "[1072 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"beliefbank_data/calibration_questions.csv\", header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Is an albatross a bird?', 'Yes'], ['Is an albatross a seabird?', 'Yes']]\n"
     ]
    }
   ],
   "source": [
    "def load_file(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        return [line.strip().split(sep=\"|\") for line in file]\n",
    "        \n",
    "print(load_file('beliefbank_data/calibration_questions.csv')[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_question_answer_list(file_name, n):\n",
    "     # n = # of (q, a) pairs to use\n",
    "\n",
    "    q_and_a = load_file(file_name)\n",
    "    questions, answers = np.split(np.array(q_and_a), 2, axis=1)\n",
    "    questions = [\"$answer$ ; $mcoptions$ = (A) yes (B) no; $question$ = \" + item + \"?\"\\\n",
    "         for sublist in questions for item in sublist]\n",
    "    answers = [item for sublist in answers for item in sublist]\n",
    "\n",
    "    question_list = list(questions)[:n]\n",
    "    answer_list = list(answers)[:n]\n",
    "    # print(question_list, answer_list)\n",
    "    return question_list, answer_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run MACAW on file with questions and answers\n",
    "def batch_eval(file_name, n):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    question_list, answer_list = create_question_answer_list(file_name, n)\n",
    "\n",
    "    inputs_dict = tokenizer.batch_encode_plus(question_list, max_length = 200, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs_dict.input_ids.to(device)\n",
    "\n",
    "    labels = tokenizer.batch_encode_plus(answer_list, max_length = 3, padding=True, truncation=True, return_tensors='pt')\\\n",
    "        .input_ids.to(device)\n",
    "\n",
    "    output = model.generate(input_ids, max_length=200)\n",
    "    answers = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "    return answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$answer$ = yes', '$answer$ = yes', '$answer$ = yes', '$answer$ = yes', '$answer$ = yes']\n"
     ]
    }
   ],
   "source": [
    "ans = batch_eval(\"beliefbank_data/calibration_questions.csv\", 5)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run MACAW supervised training on file with questions and answers\n",
    "# this function is really similar to batch_eval; only difference is that labels (answers) are included and used \n",
    "# to run the forward-pass of the model on. the output is the logits / loss.\n",
    "# see: https://huggingface.co/docs/transformers/model_doc/t5#training\n",
    "\n",
    "def train(file_name, n):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    question_list, answer_list = create_question_answer_list(file_name, n)\n",
    "\n",
    "    inputs_dict = tokenizer.batch_encode_plus(question_list, max_length = 200, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs_dict.input_ids.to(device)\n",
    "\n",
    "    labels = tokenizer.batch_encode_plus(answer_list, max_length = 3, padding=True, truncation=True, return_tensors='pt')\\\n",
    "        .input_ids.to(device)\n",
    "\n",
    "    # instead of generate, call forward-pass of function \n",
    "    logits = model(input_ids=input_ids, labels=labels).logits\n",
    "    logits_softmax = torch.nn.functional.softmax(logits, dim = 1)\n",
    "    print(logits_softmax)\n",
    "\n",
    "    loss = model(input_ids=input_ids, labels=labels).loss\n",
    "    print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.4745e-01, 7.0000e-09, 9.9592e-06,  ..., 2.2646e-02,\n",
      "          2.6023e-02, 1.9308e-02],\n",
      "         [7.5255e-01, 1.0000e+00, 9.9999e-01,  ..., 9.7735e-01,\n",
      "          9.7398e-01, 9.8069e-01]],\n",
      "\n",
      "        [[3.4996e-01, 3.6346e-08, 2.6528e-05,  ..., 1.8303e-02,\n",
      "          2.0485e-02, 1.5737e-02],\n",
      "         [6.5004e-01, 1.0000e+00, 9.9997e-01,  ..., 9.8170e-01,\n",
      "          9.7951e-01, 9.8426e-01]],\n",
      "\n",
      "        [[8.5406e-02, 8.4951e-09, 3.7509e-05,  ..., 1.0096e-03,\n",
      "          1.1446e-03, 8.7485e-04],\n",
      "         [9.1459e-01, 1.0000e+00, 9.9996e-01,  ..., 9.9899e-01,\n",
      "          9.9886e-01, 9.9913e-01]]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor(24.1662, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train(\"beliefbank_data/silver_questions.csv\", 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Basic Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macaw_evaluate(n):\n",
    "    macaw_pred = batch_eval(\"beliefbank_data/calibration_questions.csv\", n)\n",
    "    macaw_pred = [item[len('$answer$ = '):] for item in macaw_pred] # remove '$answer$ = '\n",
    "    _ , truth = create_question_answer_list(\"beliefbank_data/calibration_questions.csv\", n)\n",
    "    # print(macaw_pred, truth)\n",
    "\n",
    "    correct = 0\n",
    "    for idx in range(n):\n",
    "        if(macaw_pred[idx].lower() == truth[idx].lower()):\n",
    "            correct += 1\n",
    "    return correct / n # proportion of correct macaw preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no'] ['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macaw_evaluate(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sample by looking at constraints and finding a contradiction there\n",
    "- or pick an entity and multiple facts about it (one-to-many mapping)\n",
    "\n",
    "\n",
    "- no train set, only a validation set and test set. (split dataset in two, hold out some entities for test set)\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4a174f9e1d31d9a365b2c26615a8dc2bf9473bcc2483aeb7d2d4cf28f830d3b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cs224n_proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
