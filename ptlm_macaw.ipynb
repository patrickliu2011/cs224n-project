{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACAW Question Answering\n",
    "CS 224N Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# Macaw-large, PTLM \n",
    "# https://github.com/allenai/macaw\n",
    "# This was used in the BeliefBank Paper\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads a pretty large model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/macaw-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/macaw-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example output for a simple question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$answer$ = no']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string = \"$answer$ ; $mcoptions$ = (A) yes (B) no; $question$ = Is a robin a virus?\"\n",
    "input_ids = tokenizer.encode(input_string, return_tensors=\"pt\")\n",
    "output = model.generate(input_ids, max_length=200)\n",
    "\n",
    "tokenizer.batch_decode(output, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is an albatross a bird?|Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is an albatross a seabird?|Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is an albatross an animal?|Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is an albatross a eukaryotic_organism?|Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is an albatross a pelagic_bird?|Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>Is a daffodil a palm tree?|No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>Is a daffodil a crustacean?|No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>Is a daffodil a jellyfish?|No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>Is a daffodil an invertebrate?|No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>Is a daffodil a rodent?|No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1072 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0\n",
       "0                    Is an albatross a bird?|Yes\n",
       "1                 Is an albatross a seabird?|Yes\n",
       "2                 Is an albatross an animal?|Yes\n",
       "3     Is an albatross a eukaryotic_organism?|Yes\n",
       "4            Is an albatross a pelagic_bird?|Yes\n",
       "...                                          ...\n",
       "1067               Is a daffodil a palm tree?|No\n",
       "1068              Is a daffodil a crustacean?|No\n",
       "1069               Is a daffodil a jellyfish?|No\n",
       "1070           Is a daffodil an invertebrate?|No\n",
       "1071                  Is a daffodil a rodent?|No\n",
       "\n",
       "[1072 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"beliefbank_data/calibration_questions.csv\", header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Is an albatross a bird?', 'Yes'], ['Is an albatross a seabird?', 'Yes']]\n"
     ]
    }
   ],
   "source": [
    "def load_file(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        return [line.strip().split(sep=\"|\") for line in file]\n",
    "        \n",
    "print(load_file('beliefbank_data/calibration_questions.csv')[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_question_answer_list(file_name, n):\n",
    "     # n = # of (q, a) pairs to use\n",
    "\n",
    "    q_and_a = load_file(file_name)\n",
    "    questions, answers = np.split(np.array(q_and_a), 2, axis=1)\n",
    "    questions = [\"$answer$ ; $mcoptions$ = (A) yes (B) no; $question$ = \" + item \\\n",
    "         for sublist in questions for item in sublist]\n",
    "    answers = [item for sublist in answers for item in sublist]\n",
    "\n",
    "    question_list = list(questions)[:n]\n",
    "    answer_list = list(answers)[:n]\n",
    "    # print(question_list, answer_list)\n",
    "    return question_list, answer_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate MACAW on our question list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates MACAW on the questions list (input)\n",
    "def batch_eval(file_name, n):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    question_list, _ = create_question_answer_list(file_name, n)\n",
    "\n",
    "    inputs_dict = tokenizer.batch_encode_plus(question_list, max_length = 200, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs_dict.input_ids.to(device)\n",
    "\n",
    "    output = model.generate(input_ids, max_length=200)\n",
    "    answers = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "    return answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$answer$ = yes', '$answer$ = yes', '$answer$ = yes', '$answer$ = yes', '$answer$ = yes']\n"
     ]
    }
   ],
   "source": [
    "ans = batch_eval(\"beliefbank_data/calibration_questions.csv\", 5)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[9.9993e-01, 2.9274e-11, 1.6404e-04,  ..., 9.8557e-01,\n",
      "          9.8302e-01, 9.8291e-01],\n",
      "         [2.6385e-08, 2.3399e-13, 2.2940e-02,  ..., 7.2222e-05,\n",
      "          9.2733e-05, 1.1006e-04],\n",
      "         [2.5865e-07, 5.6556e-14, 3.0727e-05,  ..., 2.7700e-08,\n",
      "          4.8382e-08, 2.1112e-08],\n",
      "         ...,\n",
      "         [3.6993e-11, 1.1108e-13, 1.5797e-01,  ..., 1.4055e-11,\n",
      "          1.9758e-11, 1.4695e-11],\n",
      "         [9.0024e-06, 1.1401e-10, 8.5915e-05,  ..., 1.6595e-05,\n",
      "          1.4385e-05, 2.4910e-05],\n",
      "         [5.8977e-05, 1.0000e+00, 4.1737e-02,  ..., 1.4342e-02,\n",
      "          1.6874e-02, 1.6954e-02]],\n",
      "\n",
      "        [[9.9996e-01, 3.2006e-11, 1.7964e-04,  ..., 9.9845e-01,\n",
      "          9.9820e-01, 9.9812e-01],\n",
      "         [3.3889e-08, 3.4629e-13, 3.1626e-02,  ..., 1.9254e-04,\n",
      "          2.4761e-04, 2.9026e-04],\n",
      "         [4.4414e-07, 8.4894e-14, 3.4328e-05,  ..., 8.8814e-08,\n",
      "          1.5721e-07, 6.8148e-08],\n",
      "         ...,\n",
      "         [5.9780e-11, 1.3411e-13, 1.5178e-01,  ..., 3.6938e-11,\n",
      "          5.2567e-11, 3.9032e-11],\n",
      "         [1.7339e-05, 1.0328e-10, 3.5824e-05,  ..., 4.8820e-06,\n",
      "          4.3359e-06, 7.0449e-06],\n",
      "         [1.8126e-05, 1.0000e+00, 2.2556e-02,  ..., 1.3562e-03,\n",
      "          1.5482e-03, 1.5840e-03]],\n",
      "\n",
      "        [[9.9991e-01, 2.5550e-11, 5.0414e-04,  ..., 8.1464e-01,\n",
      "          7.9454e-01, 7.9136e-01],\n",
      "         [1.6463e-08, 1.9838e-13, 6.0455e-02,  ..., 1.3745e-04,\n",
      "          1.7107e-04, 2.0223e-04],\n",
      "         [2.1809e-07, 6.2139e-14, 7.1590e-05,  ..., 4.0241e-08,\n",
      "          6.8284e-08, 2.9456e-08],\n",
      "         ...,\n",
      "         [9.6082e-12, 2.3380e-14, 8.5103e-02,  ..., 2.3024e-12,\n",
      "          2.9752e-12, 2.1778e-12],\n",
      "         [1.2466e-05, 6.2619e-11, 2.5941e-04,  ..., 1.9874e-05,\n",
      "          1.7116e-05, 2.6724e-05],\n",
      "         [7.9614e-05, 1.0000e+00, 1.8912e-01,  ..., 1.8520e-01,\n",
      "          2.0527e-01, 2.0841e-01]],\n",
      "\n",
      "        [[9.9938e-01, 1.9277e-11, 8.0357e-05,  ..., 9.0355e-01,\n",
      "          8.9286e-01, 8.7800e-01],\n",
      "         [7.2479e-08, 3.0647e-13, 2.6983e-02,  ..., 6.6939e-04,\n",
      "          8.5649e-04, 9.9029e-04],\n",
      "         [3.8519e-07, 6.0288e-14, 2.7891e-05,  ..., 1.8261e-07,\n",
      "          3.1330e-07, 1.3611e-07],\n",
      "         ...,\n",
      "         [1.3431e-10, 1.3339e-13, 1.8909e-01,  ..., 1.1344e-10,\n",
      "          1.5783e-10, 1.1685e-10],\n",
      "         [5.0484e-04, 5.4892e-10, 4.0653e-04,  ..., 2.9931e-02,\n",
      "          2.8546e-02, 4.4713e-02],\n",
      "         [1.1402e-04, 1.0000e+00, 4.4852e-02,  ..., 6.5854e-02,\n",
      "          7.7734e-02, 7.6299e-02]]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([4, 7, 32128])\n",
      "tensor(0.9997, grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "### Runs MACAW supervised training on file with questions and answers\n",
    "# this function is really similar to batch_eval; only difference is that labels (answers) are included and used \n",
    "# to run the forward-pass of the model on. the output is the logits / loss.\n",
    "\n",
    "# see: https://huggingface.co/docs/transformers/model_doc/t5#training\n",
    "\n",
    "def train(file_name, n):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    question_list, answer_list = create_question_answer_list(file_name, n)\n",
    "    # append to answer_list the '$answer$ = ' string to match formatting from MACAW output\n",
    "    answer_list = [(\"$answer$ = \" + ans).lower() for ans in answer_list]\n",
    "\n",
    "    inputs_dict = tokenizer.batch_encode_plus(question_list, max_length = 200, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs_dict.input_ids.to(device)\n",
    "\n",
    "    labels = tokenizer.batch_encode_plus(answer_list, max_length = 15, padding=True, truncation=True, return_tensors='pt')\\\n",
    "        .input_ids.to(device) # max_length is set to len(\"$answer$ = yes\")\n",
    "\n",
    "    # instead of generate, call forward-pass of function \n",
    "    fwd = model(input_ids=input_ids, labels=labels)\n",
    "\n",
    "    # logits\n",
    "    logits = fwd.logits\n",
    "    logits_softmax = torch.nn.functional.softmax(logits, dim = 1)\n",
    "    print(logits_softmax)\n",
    "    print(logits_softmax.shape)\n",
    "\n",
    "    # loss\n",
    "    loss = fwd.loss # - log(P(y|x))\n",
    "    confidence = torch.exp(-loss)\n",
    "    print(confidence)\n",
    "\n",
    "# for i in range(20):\n",
    "train(\"beliefbank_data/silver_questions.csv\", 4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Basic Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically just output the proportion of correct Macaw predictions vs our answer list.\n",
    "def macaw_evaluate(n):\n",
    "    macaw_pred = batch_eval(\"beliefbank_data/calibration_questions.csv\", n)\n",
    "    macaw_pred = [item[len('$answer$ = '):] for item in macaw_pred] # remove '$answer$ = '\n",
    "    question , truth = create_question_answer_list(\"beliefbank_data/calibration_questions.csv\", n)\n",
    "    # print(macaw_pred, truth)\n",
    "\n",
    "    correct = 0\n",
    "    for idx in range(n):\n",
    "        if(macaw_pred[idx].lower() == truth[idx].lower()):\n",
    "            correct += 1\n",
    "        else:\n",
    "            print(\"Incorrect prediction made by Macaw: {}, Truth: {} for question # {}: {}\".\\\n",
    "                format(macaw_pred[idx], truth[idx], idx, question[idx]))\n",
    "    return correct / n # proportion of correct macaw preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect prediction made by Macaw: no, Truth: Yes for question # 11: $answer$ ; $mcoptions$ = (A) yes (B) no; $question$ = Does an albatross have a face?\n",
      "Incorrect prediction made by Macaw: no, Truth: Yes for question # 15: $answer$ ; $mcoptions$ = (A) yes (B) no; $question$ = Does an albatross have a head?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macaw_evaluate(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes for sampling (from constraints_v2.json)\n",
    "- Sample by looking at constraints and finding a contradiction there\n",
    "- or pick an entity and multiple facts about it (one-to-many mapping)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4a174f9e1d31d9a365b2c26615a8dc2bf9473bcc2483aeb7d2d4cf28f830d3b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cs224n_proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
