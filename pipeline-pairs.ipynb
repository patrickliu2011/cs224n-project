{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f75d45a7-8f30-4cf7-b64e-5645782ef09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import random\n",
    "import json\n",
    "import nltk \n",
    "import csv\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import nltk  # $ pip install nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import cmudict  # >>> nltk.download('cmudict')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "\n",
    "from beliefbank_data.utils import generate_assertion, generate_question, find_constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83360dd8-9e5a-48a4-8274-0c70e3a0361d",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03374e1c-dff7-49d5-847b-0a6816c6a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_path = \"beliefbank_data/constraints_v2.json\"\n",
    "facts_path = \"beliefbank_data/silver_facts.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05c60643-c341-4af6-9459-c8458700b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = json.load(open(constraints_path))\n",
    "facts = json.load(open(facts_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a25158-8d99-4088-b240-51b5b6423334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['american bison', 'baboon', 'birch', 'buck', 'bull', 'calf', 'camel', 'carnivore', 'carp', 'cheetah', 'chick', 'chimpanzee', 'cock', 'crocodile', 'dog', 'dolphin', 'domestic ass', 'duck', 'earthworm', 'elephant', 'european wolf spider', 'foxhound', 'frog', 'gazelle', 'gecko', 'german shepherd', 'giant panda', 'giraffe', 'gladiolus', 'hen', 'horse', 'hound', 'howler monkey', 'hummingbird', 'jaguar', 'lamb', 'leopard', 'lion', 'livestock', 'llama', 'magpie', 'midge', 'mink', 'mullet', 'myna', 'new world blackbird', 'orchid', 'owl', 'ox', 'penguin', 'peony', 'pigeon', 'poodle', 'puppy', 'rabbit', 'rat', 'reptile', 'robin', 'rose', 'salamander', 'starling', 'tiger', 'turkey', 'whale', 'zebra']\n"
     ]
    }
   ],
   "source": [
    "# entities = list(facts.keys())\n",
    "# random.shuffle(entities)\n",
    "# dev_size = 65\n",
    "# dev_entities = sorted(entities[:dev_size])\n",
    "# eval_entities = sorted(entities[dev_size:])\n",
    "# with open(\"beliefbank_data/dev_entities.txt\", \"w\") as f:\n",
    "#     f.writelines([e + '\\n' for e in dev_entities])\n",
    "# with open(\"beliefbank_data/eval_entities.txt\", \"w\") as f:\n",
    "#     f.writelines([e + '\\n' for e in eval_entities])\n",
    "\n",
    "with open(\"beliefbank_data/dev_entities.txt\", \"r\") as f:\n",
    "    dev_entities = [e.strip() for e in f.readlines()]\n",
    "print(dev_entities)\n",
    "\n",
    "# with open(\"beliefbank_data/eval_entities.txt\", \"r\") as f:\n",
    "#     eval_entities = [e.strip() for e in f.readlines()]\n",
    "# print(eval_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31eb8693-c486-4cbb-9070-4f84b074d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of facts: 9640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('american bison', 'IsA,mammal', True),\n",
       " ('american bison', 'IsA,american bison', True),\n",
       " ('american bison', 'IsA,animal', True),\n",
       " ('american bison', 'IsA,vertebrate', True),\n",
       " ('american bison', 'IsA,warm blooded animal', True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statements = [(entity, relation, label == 'yes')\n",
    "              for entity, relations in facts.items() if entity in dev_entities \n",
    "              for relation, label in relations.items()]\n",
    "print(f\"Number of facts: {len(statements)}\")\n",
    "statements[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ad53a-5ebc-4366-916e-534c78d69f44",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2dd540c-0d05-4fec-85cc-6309b64a4764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "699dba1b-3171-4690-be58-a5fd082e80d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads a pretty large model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/macaw-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/macaw-large\")\n",
    "model = model.to(device=device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5f170c9-5046-4905-b309-e7a821357467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA Model stuff\n",
    "def format_question(question_list):\n",
    "    question_list = [\"$answer$ ; $mcoptions$ = (A) yes (B) no; $question$ = \" + item \\\n",
    "         for item in question_list]\n",
    "    return question_list\n",
    "\n",
    "def predict(question_list):\n",
    "    B = len(question_list)\n",
    "    question_list = format_question(question_list)\n",
    "    answer_list_all_yes = [\"$answer$ = yes\"] * B     # pass in list of \"yes\"\n",
    "    \n",
    "    # print(dir(tokenizer))\n",
    "    inputs = tokenizer.batch_encode_plus(question_list, max_length = 256, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    labels = tokenizer.batch_encode_plus(answer_list_all_yes, max_length = 15, padding=True, truncation=True, return_tensors=\"pt\") # max_length is set to len(\"$answer$ = yes\")\n",
    "    \n",
    "    # output = model.generate(input_ids, max_length=200)\n",
    "    # answers = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    fwd = model(input_ids=inputs[\"input_ids\"].to(device), attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                # decoder_input_ids=labels[\"input_ids\"], decoder_attention_mask=labels[\"attention_mask\"])\n",
    "                labels=labels[\"input_ids\"].to(device))\n",
    "    # output_ids = torch.argmax(fwd.logits, dim=-1)\n",
    "    # print(tokenizer.batch_decode(output_ids, skip_special_tokens=True))\n",
    "\n",
    "    # loss\n",
    "    # loss = fwd.loss # - log(P(y|x))\n",
    "    # confidence = torch.exp(-loss)\n",
    "    logits = fwd.logits.reshape((B, 7, -1))\n",
    "    logits = logits[:, 5, :] # Index of yes/no token in answer\n",
    "    probs = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    # yes has input_id 4273, no has input_id 150\n",
    "    confidence_yes = probs[..., 4273] \n",
    "    confidence_no = probs[..., 150]\n",
    "    \n",
    "    answers = (confidence_yes >= confidence_no) # np.array([(ans == \"$answer$ = yes\") for ans in answers])\n",
    "    confidences = np.where(answers, confidence_yes, confidence_no)\n",
    "\n",
    "    return answers, confidences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59effc47-e588-4c7b-8e90-82bf14a9e4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "nli_tokenizer = AutoTokenizer.from_pretrained(\"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\")\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(\"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\")\n",
    "nli_model = nli_model.to(device=device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1970157b-6933-4d87-b772-300891b1b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contradiction_matrix(sents, nli_tokenizer, nli_model):\n",
    "    \"\"\"Generates contradiction matrix of shape (N, B, B)\"\"\"\n",
    "    if sents.ndim == 1:\n",
    "        sents = sents.reshape(1, -1)\n",
    "    \n",
    "    N, B = sents.shape\n",
    "    prem = []\n",
    "    hypo = []\n",
    "    for i in range(N):\n",
    "        for j in range(B):\n",
    "            for k in range(B):\n",
    "                prem.append(sents[i][j])\n",
    "                hypo.append(sents[i][k])\n",
    "\n",
    "    tokenized = nli_tokenizer(prem, hypo, \n",
    "                              max_length=256, \n",
    "                              return_token_type_ids=True, \n",
    "                              truncation=True,\n",
    "                              padding=True)\n",
    "    \n",
    "    input_ids = torch.Tensor(tokenized['input_ids']).to(device).long()\n",
    "    token_type_ids = torch.Tensor(tokenized['token_type_ids']).to(device).long()\n",
    "    attention_mask = torch.Tensor(tokenized['attention_mask']).to(device).long()\n",
    "    \n",
    "    nli_outputs = nli_model(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            labels=None)\n",
    "    predicted_probability = torch.softmax(nli_outputs.logits, dim=1)\n",
    "    contra_matrix = predicted_probability[..., 2]\n",
    "    contra_matrix = contra_matrix.reshape(N, B, B)\n",
    "    return contra_matrix.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8e59a46-e727-479b-99ba-0475fb2a7e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction methods\n",
    "# predictions: (N, B) bool\n",
    "# confidences: (N, B) float\n",
    "# contra_matrix: (N, B, B) float\n",
    "def do_nothing(predictions, confidences, contra_matrix):\n",
    "    return predictions\n",
    "\n",
    "def correction_1(predictions, confidences, contra_matrix):\n",
    "    contra_matrix_sym = (contra_matrix + contra_matrix.T) / 2\n",
    "    contra_prob = contra_matrix[:, 0, 1] # (N,)\n",
    "    flip = (contra_prob > 0.5)\n",
    "    flip1 = confidences[:, 0] > confidences[:, 1] # (N, )\n",
    "    flip0 = flip * np.logical_not(flip1) # locations to flip first statement\n",
    "    flip1 = flip * flip1 # locations to flip second statement\n",
    "    \n",
    "    corrected = predictions.copy()\n",
    "    corrected[flip0, 0] = np.logical_not(corrected[flip0, 0])\n",
    "    corrected[flip1, 1] = np.logical_not(corrected[flip1, 1])\n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8c32a7b-1055-4fa5-acc5-3ddc77d90e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True],\n",
       "       [ True,  True]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array([[True, True], [True, False]])\n",
    "confidences = np.array([[0.5, 0.7], [0.7, 0.5]])\n",
    "contra_matrix = np.array([[[0, 1], [1, 0]], [[0, 1], [1, 0]]])\n",
    "correction_1(predictions, confidences, contra_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9566f12a-18af-4d2a-a705-b56d55ca9f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions, answers):\n",
    "    if predictions.ndim == 1:\n",
    "        predictions = predictions.reshape(1, -1)\n",
    "    answers = answers.reshape(predictions.shape)\n",
    "    \n",
    "    actual_answers = answers.copy()\n",
    "    actual_answers[:, 1:] = np.logical_not(actual_answers[:, 1:])\n",
    "    acc = np.sum(predictions == actual_answers)\n",
    "    \n",
    "    con = np.all(predictions == answers, axis=1)\n",
    "    con = np.count_nonzero(con)\n",
    "    \n",
    "    total = predictions.size\n",
    "    bsize = predictions.shape[0]\n",
    "    return acc, con, total, bsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88143abe-885c-499c-bcfc-40304aa1edf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4645: 100 batches, 1000 pairs\n",
      "\tAccurate 1406 / 2000 = 0.703\n",
      "\tContradictions 69 / 1000 = 0.069\n",
      "Iter 9192: 200 batches, 2000 pairs\n",
      "\tAccurate 2794 / 4000 = 0.6985\n",
      "\tContradictions 155 / 2000 = 0.0775\n",
      "Iter 4156: 300 batches, 3000 pairs\n",
      "\tAccurate 4203 / 6000 = 0.7005\n",
      "\tContradictions 256 / 3000 = 0.08533333333333333\n",
      "Iter 8696: 400 batches, 4000 pairs\n",
      "\tAccurate 5608 / 8000 = 0.701\n",
      "\tContradictions 329 / 4000 = 0.08225\n",
      "Iter 3716: 500 batches, 5000 pairs\n",
      "\tAccurate 6981 / 10000 = 0.6981\n",
      "\tContradictions 413 / 5000 = 0.0826\n",
      "Iter 8445: 600 batches, 6000 pairs\n",
      "\tAccurate 8376 / 12000 = 0.698\n",
      "\tContradictions 483 / 6000 = 0.0805\n",
      "Iter 3596: 700 batches, 7000 pairs\n",
      "\tAccurate 9745 / 14000 = 0.6960714285714286\n",
      "\tContradictions 573 / 7000 = 0.08185714285714285\n",
      "Iter 8039: 800 batches, 8000 pairs\n",
      "\tAccurate 11133 / 16000 = 0.6958125\n",
      "\tContradictions 664 / 8000 = 0.083\n",
      "Iter 2961: 900 batches, 9000 pairs\n",
      "\tAccurate 12501 / 18000 = 0.6945\n",
      "\tContradictions 746 / 9000 = 0.08288888888888889\n",
      "Iter 7566: 1000 batches, 10000 pairs\n",
      "\tAccurate 13869 / 20000 = 0.69345\n",
      "\tContradictions 826 / 10000 = 0.0826\n",
      "Accurate 13869 / 20000 questions = 0.69345\n",
      "Contradictions 826 / 10000 pairs = 0.0826\n",
      "Runtime: 224.9394154548645\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "acc_count = 0\n",
    "con_count = 0\n",
    "total_count = 0\n",
    "num_pairs = 0\n",
    "\n",
    "batch_size = 10\n",
    "batch_counter = 0\n",
    "num_batches = 0\n",
    "batch = []\n",
    "\n",
    "explored_pairs = set()\n",
    "random.shuffle(statements)\n",
    "idx = 0\n",
    "while num_pairs < 10000:\n",
    "    if idx == len(statements) - 1:\n",
    "        random.shuffle(statements)\n",
    "        idx = 0\n",
    "    base = statements[idx]\n",
    "    idx += 1\n",
    "    \n",
    "    base = random.choice(statements)\n",
    "    entity, relation, true = base\n",
    "    \n",
    "    if true:\n",
    "        filter_dict = {\n",
    "            'source': relation,\n",
    "            'direction': 'forward',\n",
    "        }\n",
    "        selected_constraints = find_constraints(constraints, filter_dict=filter_dict)\n",
    "    else:\n",
    "        filter_dict = {\n",
    "            'weight': 'yes_yes',\n",
    "            'target': relation,\n",
    "            'direction': 'forward',\n",
    "        }\n",
    "        selected_constraints = find_constraints(constraints, filter_dict=filter_dict)\n",
    "    if len(selected_constraints) == 0:\n",
    "        continue\n",
    "    c = random.choice(selected_constraints)\n",
    "    contra = (entity, c['target'] if true else c['source'], true != (c['weight'] == 'yes_yes'))\n",
    "    pair = (base, contra)\n",
    "    while pair in explored_pairs:\n",
    "        selected_constraints.remove(c)\n",
    "        if len(selected_constraints) == 0:\n",
    "            continue\n",
    "        c = random.choice(selected_constraints)\n",
    "        contra = (entity, c['target'], not (c['weight'] == 'yes_yes'))\n",
    "        pair = (base, contra)\n",
    "    pair = list(pair)\n",
    "    # print(base, contra)\n",
    "    \n",
    "    # Collect pairs in batches\n",
    "    if batch_counter == 0:\n",
    "        batch = []\n",
    "    batch_counter += 1\n",
    "    batch.extend(pair)\n",
    "    if batch_counter < batch_size: # Batch not full yet, keep accumulating examples\n",
    "        continue\n",
    "    # We have a full batch\n",
    "    batch_counter = 0\n",
    "    num_batches += 1\n",
    "    \n",
    "    questions, answers = zip(*[generate_question(*tup) for tup in batch])\n",
    "    question_list = list(questions)\n",
    "    answer_list = np.array([ans == \"Yes\" for ans in answers])\n",
    "    # print(\"Questions:\", question_list)\n",
    "    # print(\"Labels (for contradiction):\", answer_list)\n",
    "    \n",
    "    predictions, confidences = predict(question_list)\n",
    "    predictions = predictions.flatten()\n",
    "    confidences = confidences.flatten()\n",
    "    # print(\"QA predictions:\", predictions)\n",
    "    # print(\"QA confidences:\", confidences)\n",
    "    \n",
    "    pred_batch = [(ent, rel, predictions[i]) for i, (ent, rel, true) in enumerate(batch)]\n",
    "    assertions = [generate_assertion(*tup) for tup in pred_batch]\n",
    "    # print(\"Assertions:\", assertions)\n",
    "    \n",
    "    assertions = np.array(assertions).reshape(batch_size, -1)\n",
    "    contra_matrix = contradiction_matrix(assertions, nli_tokenizer, nli_model)\n",
    "    # print(\"Contradiction probability matrix:\\n\", contra_matrix)\n",
    "    \n",
    "    predictions = predictions.reshape(batch_size, -1)\n",
    "    confidences = confidences.reshape(batch_size, -1)\n",
    "    corrected = do_nothing(predictions, confidences, contra_matrix)\n",
    "    acc, con, total, bsize = evaluate(corrected, answer_list)\n",
    "    acc_count += acc\n",
    "    con_count += con\n",
    "    total_count += total\n",
    "    num_pairs += bsize\n",
    "    # print(acc, con, total, bsize)\n",
    "    \n",
    "    if num_batches % 100 == 0:\n",
    "        print(f\"Iter {idx}: {num_batches} batches, {num_pairs} pairs\")\n",
    "        print(f\"\\tAccurate {acc_count} / {total_count} = {acc_count / total_count}\")\n",
    "        print(f\"\\tContradictions {con_count} / {num_pairs} = {con_count / num_pairs}\")\n",
    "    \n",
    "print(f\"Accurate {acc_count} / {total_count} questions = {acc_count / total_count}\")\n",
    "print(f\"Contradictions {con_count} / {num_pairs} pairs = {con_count / num_pairs}\")\n",
    "\n",
    "end = time.time()\n",
    "print(\"Runtime:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e71d0f-b54c-415e-a33f-a0180aae85b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4a174f9e1d31d9a365b2c26615a8dc2bf9473bcc2483aeb7d2d4cf28f830d3b"
  },
  "kernelspec": {
   "display_name": "contradiction",
   "language": "python",
   "name": "contradiction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
