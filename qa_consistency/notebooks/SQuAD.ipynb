{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "import numpy as np\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcotcr/work/implication-acl/env/lib/python3.6/site-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import qa_consistency\n",
    "import qa_consistency.dataset_utils\n",
    "import qa_consistency.implication\n",
    "import os\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: generating implications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Did not use initialization regex that was passed: .*bias_hh.*\n",
      "Did not use initialization regex that was passed: .*weight_ih.*\n",
      "Did not use initialization regex that was passed: .*bias_ih.*\n",
      "Did not use initialization regex that was passed: .*weight_hh.*\n"
     ]
    }
   ],
   "source": [
    "gen = qa_consistency.implication.ImplicationsSquad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your label namespace was 'pos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Who died in 1285?', 'Zhenjin', 'subj')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage = 'Kublai originally named his eldest son, Zhenjin, as the Crown Prince, \\\n",
    "but he died before Kublai in 1285.'\n",
    "gen.implications('When did Zhenjin die?', '1285', passage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating implications for all possible squad answers on dev dataset. You can skip this and load my precomputed implications below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, answers = qa_consistency.dataset_utils.load_squad('/home/marcotcr/datasets/squad/')\n",
    "answer_texts = [[x[0] for x in y] for y in answers]\n",
    "questions = [x['question'].strip() for x in data]\n",
    "passages = [x['passage'].strip() for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qs, all_as, all_contexts = qa_consistency.dataset_utils.question_answers_context_product(questions, answer_texts, passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encountered the arc_loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n",
      "Encountered the tag_loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n",
      "Encountered the loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in  Q: What light radiation does ozone absorb?\n",
      "A: ultraviolet\n"
     ]
    }
   ],
   "source": [
    "parsed_dataset = gen.parse_dataset(all_qs, all_as, all_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "implications = [gen.implications_from_parsed(x) for x in parsed_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8754 Q: J. A. Hobson wanted which races to develop the world?\n",
      "A: of highest 'social efficiency\n",
      "D: J. A. Hobson wanted of highest 'social efficiency to develop the world.\n",
      "('Who wanted of highest social efficiency to develop the world?', 'J. A. Hobson', 'subj')\n",
      "\n",
      "12665 Q: What was the name of the contest sponsored by QuickBooks?\n",
      "A: Small Business Big Game\n",
      "D: The name of the contest sponsored by QuickBooks was Small Business Big Game .\n",
      "('The name of the contest sponsored by what was Small Business Big Game ?', 'QuickBooks', 'what')\n",
      "\n",
      "14166 Q: What was the Disneyland anthology series retitled in 1958?\n",
      "A: Walt Disney Presents\n",
      "D: The Disneyland anthology series was retitled in Walt Disney Presents 1958.\n",
      "('What was retitled in Walt Disney Presents 1958?', 'Disneyland anthology series', 'subj')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idxs = np.random.choice(len(implications), 5, replace=False)\n",
    "for i in idxs:\n",
    "    if not implications[i]:\n",
    "        continue\n",
    "    print(i, parsed_dataset[i])\n",
    "    for x in implications[i]:\n",
    "        print(x)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/home/marcotcr/tmp/'\n",
    "squad_path = '/home/marcotcr/datasets/squad/dev-v1.1.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imps = {}\n",
    "for qa, imp in zip(parsed_dataset, implications):\n",
    "    all_imps[qa.as_tuple()] = imp\n",
    "pickle.dump(all_imps, open(os.path.join(output_folder, \"squad_imps.pkl\"), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start from here if you want to use precomputed implications (link to pkl file in the repository's README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/home/marcotcr/tmp/'\n",
    "squad_path = '/home/marcotcr/datasets/squad/dev-v1.1.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imps = pickle.load(open(os.path.join(output_folder, \"squad_imps.pkl\"), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_jsonl_path = os.path.join(output_folder, 'dev_allennlp.jsonl')\n",
    "squad_preds_jsonl = os.path.join(output_folder, 'squad_dev_preds.jsonl')\n",
    "squad_preds_json = os.path.join(output_folder, 'squad_dev_preds.json')\n",
    "squad_consistency_path  = os.path.join(output_folder, 'squad_consistency.json')\n",
    "squad_consistency_jsonl  = os.path.join(output_folder, 'squad_consistency.jsonl')\n",
    "squad_consistency_preds_jsonl = os.path.join(output_folder, 'squad_consistency_preds.jsonl')\n",
    "squad_consistency_preds_json = os.path.join(output_folder, 'squad_consistency_preds.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using allennlp, so we need to convert the original dataset to a jsonl file before getting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_consistency.dataset_utils.squad_to_allennlp(squad_path, squad_jsonl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "allennlp predict https://s3-us-west-2.amazonaws.com/allennlp/models/bidaf-model-2017.09.15-charpad.tar.gz /home/marcotcr/tmp/dev_allennlp.jsonl --output-file /home/marcotcr/tmp//home/marcotcr/tmp/squad_dev_preds.jsonl --cuda-device 0 --silent\n"
     ]
    }
   ],
   "source": [
    "print('Run:')\n",
    "print('allennlp predict https://s3-us-west-2.amazonaws.com/allennlp/models/bidaf-model-2017.09.15-charpad.tar.gz\\\n",
    " %s --output-file /home/marcotcr/tmp/%s --cuda-device 0 --silent' % (squad_jsonl_path, squad_preds_jsonl))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform allennlp output to the official squad output format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_consistency.dataset_utils.allennlp_preds_to_squad_format(squad_jsonl_path, squad_preds_jsonl, squad_preds_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a consistency dataset to check exact match predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_consistency.dataset_utils.generate_implication_squad(squad_path,\n",
    "                                                        squad_preds_json,\n",
    "                                                        all_imps,\n",
    "                                                        squad_consistency_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert datset to jsonl (for allennlp):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_consistency.dataset_utils.squad_to_allennlp(squad_consistency_path, squad_consistency_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "allennlp predict https://s3-us-west-2.amazonaws.com/allennlp/models/bidaf-model-2017.09.15-charpad.tar.gz /home/marcotcr/tmp/squad_consistency.jsonl --output-file /home/marcotcr/tmp//home/marcotcr/tmp/squad_consistency_preds.jsonl --cuda-device 0 --silent\n"
     ]
    }
   ],
   "source": [
    "print('Run:')\n",
    "print('allennlp predict https://s3-us-west-2.amazonaws.com/allennlp/models/bidaf-model-2017.09.15-charpad.tar.gz\\\n",
    " %s --output-file /home/marcotcr/tmp/%s --cuda-device 0 --silent' % (squad_consistency_jsonl, squad_consistency_preds_jsonl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert allennlp output to squad format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_consistency.dataset_utils.allennlp_preds_to_squad_format(squad_consistency_jsonl, squad_consistency_preds_jsonl, squad_consistency_preds_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate consistency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency by implication type:\n",
      "\n",
      "prep : 74.0\n",
      "dobj : 68.0\n",
      "subj : 70.5\n",
      "amod : 75.1\n",
      "\n",
      "Avg  : 72.9\n"
     ]
    }
   ],
   "source": [
    "stats = qa_consistency.dataset_utils.evaluate_consistency_squad(squad_consistency_path, squad_consistency_preds_json)\n",
    "print('Consistency by implication type:')\n",
    "print()\n",
    "for x, v in stats.items():\n",
    "    if x == 'all':\n",
    "        continue\n",
    "    print('%s : %.1f' % (x, 100* v))\n",
    "print()\n",
    "print('Avg  : %.1f' % (100 * stats['all']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "implication_test",
   "language": "python",
   "name": "implication_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
